# Beschreibungsverarbeitung √ºber OpenWebUI

Dieses Projekt l√§dt Beschreibungen aus einer Datenbank, verarbeitet sie √ºber eine OpenWebUI-API (mit KI-Modellen wie Llama) und speichert die strukturierten JSON-Ergebnisse. Zus√§tzlich k√∂nnen alle Vergleichsdaten in eine CSV-Datei exportiert werden.

## Features

- ‚úÖ Automatische Verarbeitung von Beschreibungen in zwei Sprachen
- ‚úÖ JSON-Ausgabe mit semantischen Konzepten und Vergleichen
- ‚úÖ Retry-Logik bei API-Fehlern
- ‚úÖ CSV-Export aller Vergleichsdaten
- ‚úÖ Zeitstempel und Ausf√ºhrungszeit in Metadaten
- ‚úÖ Konfigurierbar √ºber YAML-Datei
- ‚úÖ Farbige Terminal-Ausgabe mit API-Call-Counter

## Projektstruktur

```
project_root/
  config.yaml              # Konfigurationsdatei (wird nicht committet)
  config.example.yaml      # Beispiel-Konfiguration
  prompt.txt               # System-/Instruktionsprompt
  requirements.txt         # Python-Abh√§ngigkeiten
  src/
    __init__.py
    config_loader.py       # YAML-Konfiguration laden
    db_client.py           # Datenbank-Zugriff
    openwebui_client.py    # OpenWebUI-API-Client
    processor.py           # Verarbeitungslogik
    csv_exporter.py        # CSV-Export-Funktionalit√§t
    main.py                # Einstiegspunkt f√ºr Verarbeitung
    export_csv.py          # Einstiegspunkt f√ºr CSV-Export
  logs/                    # Log-Dateien
  output_json/             # Generierte JSON-Dateien
  csv/                     # Exportierte CSV-Dateien
```

## Installation

1. Python 3.10+ erforderlich

2. Abh√§ngigkeiten installieren:
```bash
pip install -r requirements.txt
```

## Konfiguration

### 1. `config.yaml` anpassen

Passe die Datenbankverbindung, API-Einstellungen und Verarbeitungsparameter an:

```yaml
database:
  driver: "postgresql"
  host: "localhost"
  port: 5432
  user: "dein_user"
  password: "dein_password"
  name: "deine_datenbank"
  query: |
    SELECT
      id,
      description_column_1 as field1,
      description_column_2 as field2
    FROM descriptions
    WHERE processed = FALSE

api:
  base_url: "http://localhost:11434"
  endpoint: "/api/chat/completions"
  api_key: "your-api-key-here"
  model: "llama-3.3-70b-instruct"
  languages:
    field1: "de"
    field2: "en"
  timeout_seconds: 60
  max_retries: 3
  retry_delay_seconds: 3

processing:
  output_dir: "output_json"
  required_keys:
    - "konzepte"
    - "vergleich"
```

**Hinweise:**
- **driver**: Unterst√ºtzt `postgresql`, `mysql+pymysql`, `sqlite` etc.
- **query**: SQL-Query muss die Felder `id`, `field1`, `field2` zur√ºckgeben (mit AS-Alias)
- **api_key**: API-Schl√ºssel f√ºr die Authentifizierung (optional, falls die API keinen Key ben√∂tigt)
- **languages**: ISO-Codes (zweistellig) f√ºr field1 und field2 - werden im Prompt an die KI √ºbergeben
- **required_keys**: JSON-Validierung pr√ºft auf diese Top-Level-Keys (muss zum Prompt-Schema passen)

### 2. `prompt.txt` anpassen

Definiere den System-/Instruktionsprompt, der das gew√ºnschte JSON-Schema vorgibt:

```
Du bist ein System, das aus ikonographischen Beschreibungen Konzepte extrahiert und vergleicht.
Liefere ausschlie√ülich g√ºltigen JSON mit folgendem Schema:

{
  "original": { "de": "...", "en": "..." },
  "konzepte": { "de": [...], "en": [...] },
  "vergleich": [
    {
      "konzept_de": "...",
      "konzept_en": "...",
      "similarity": 0-100,
      "abweichung": true/false,
      "beschreibung": "..."
    }
  ]
}

Gib keine erkl√§renden Texte aus, nur reinen JSON.
```

**Wichtig:** Die `required_keys` in `config.yaml` m√ºssen mit dem Prompt-Schema √ºbereinstimmen!
  "abweichungen": [...]
}

Gib keine erkl√§renden Texte aus, nur reinen JSON.
```

## Verwendung

### 1. Beschreibungen verarbeiten (Haupt-Workflow)

**Standard-Ausf√ºhrung:**

```bash
cd src
python main.py
```

oder vom Projektroot:

```bash
python src/main.py
```

**Mit benutzerdefinierten Pfaden:**

```bash
python src/main.py --config /pfad/zu/config.yaml --prompt /pfad/zu/prompt.txt
```

**Kommandozeilen-Optionen:**

```bash
python src/main.py --help
```

- `--config`: Pfad zur Konfigurationsdatei (Standard: `config.yaml`)
- `--prompt`: Pfad zur Prompt-Datei (Standard: `prompt.txt`)
- `--log-file`: Pfad zur Log-Datei (Standard: `logs/processing.log`)
- `--skip-existing`: √úberspringe IDs mit existierenden JSON-Dateien (f√ºr inkrementelle Updates)
- `--update-metadata`: Aktualisiere nur Metadaten (original_texts) in existierenden JSON-Dateien ohne API-Aufruf

**Skip-Existing Modus:**

Wenn du die Verarbeitung fortsetzen m√∂chtest ohne bereits verarbeitete IDs erneut zu prozessieren:

```bash
python src/main.py --skip-existing
```

Dies ist n√ºtzlich wenn:
- Die Verarbeitung unterbrochen wurde (Strg+C, Verbindungsfehler, etc.)
- Nur neue Datens√§tze aus der Datenbank verarbeitet werden sollen
- Zeit und API-Kosten gespart werden sollen bei wiederholten Durchl√§ufen

Der Skip-Modus pr√ºft f√ºr jede ID ob bereits eine `{id}.json` Datei existiert und √ºberspringt diese dann.

**Update-Metadata Modus:**

Wenn du die Originaltexte nachtr√§glich in bereits verarbeitete JSON-Dateien eintragen m√∂chtest:

```bash
python src/main.py --update-metadata
```

Dies ist n√ºtzlich wenn:
- JSON-Dateien bereits existieren, aber noch keine `original_texts` in den Metadaten haben
- Die Datenbank aktualisiert wurde und du die aktualisierten Texte in die JSONs √ºbernehmen m√∂chtest
- Keine API-Aufrufe gemacht werden sollen (schneller und kostenfrei)

Der Update-Modus:
- Liest alle Datens√§tze aus der Datenbank
- L√§dt nur existierende JSON-Dateien
- Aktualisiert/erg√§nzt das Feld `meta.original_texts` mit den aktuellen DB-Werten
- √úberspringt IDs ohne existierende JSON-Datei

### 2. CSV-Export der Vergleichsdaten

Nach der Verarbeitung k√∂nnen alle Vergleichsergebnisse in eine CSV-Datei exportiert werden:

**Standard-Export:**

```bash
python src/export_csv.py
```

Dies liest automatisch:
- JSON-Dateien aus dem konfigurierten `output_dir` (z.B. `output_json/`)
- Sprachen aus der `config.yaml`
- Exportiert nach `csv/vergleiche.csv`

**Mit benutzerdefinierten Optionen:**

```bash
# Eigener Output-Pfad
python src/export_csv.py --output meine_vergleiche.csv

# Eigenes JSON-Verzeichnis
python src/export_csv.py --input-dir /pfad/zu/json --output export.csv

# Andere Config-Datei
python src/export_csv.py --config andere_config.yaml
```

**CSV-Format:**

Die CSV-Datei enth√§lt folgende Spalten (Semikolon-getrennt):

```csv
id;original_de;original_en;konzept_de;konzept_en;similarity;abweichung;beschreibung
1;Aphrodite stehend vor...;Aphrodite standing before...;Aphrodite stehend;Aphrodite standing;95;false;
1;Aphrodite stehend vor...;Aphrodite standing before...;Eros fliegend;Eros flying;100;false;
2;Zeus thronend...;null;Zeus thronend;null;0;true;Nur in DE vorhanden
```

Die Spaltennamen passen sich automatisch an die konfigurierten Sprachen an (z.B. `original_de`, `konzept_de` bei de/en).

**Hinweis:** Die `original_*` Spalten enthalten die vollst√§ndigen Originaltexte aus der Datenbank und werden seit der neuesten Version automatisch in den JSON-Metadaten gespeichert.

## Funktionsweise

### Verarbeitungs-Workflow

1. **Datenbankabfrage**: L√§dt Datens√§tze mit `id` und zwei Beschreibungen (field1, field2)
2. **API-Aufruf**: Sendet f√ºr jeden Datensatz einen Prompt mit beiden Beschreibungen an OpenWebUI
3. **JSON-Bereinigung**: Entfernt Markdown-Code-Bl√∂cke (```json) aus der KI-Antwort
4. **JSON-Validierung**: Pr√ºft die Antwort auf erwartete Felder (`konzepte`, `vergleich`)
5. **Retry-Logik**: Wiederholt fehlgeschlagene Anfragen bis zu `max_retries`
6. **Speicherung**: Speichert validierte Ergebnisse als `{id}.json` mit Metadaten
7. **CSV-Export**: Optional k√∂nnen alle Vergleiche in eine CSV-Datei exportiert werden

### Workflow-Diagramm

```
Datenbank ‚Üí Python-Script ‚Üí OpenWebUI-API ‚Üí KI-Modell
                                               ‚Üì
                                          JSON-Antwort
                                               ‚Üì
                                     Bereinigung & Validierung
                                               ‚Üì
                                        {id}.json Datei
                                               ‚Üì
                                   CSV-Export (optional)
                                               ‚Üì
                                        vergleiche.csv
```

## Output-Format

### JSON-Dateien

Jede generierte Datei (`{id}.json`) hat folgende Struktur:

```json
{
  "original": {
    "de": "Originalbeschreibung Deutsch",
    "en": "Original description English"
  },
  "konzepte": {
    "de": ["Konzept 1", "Konzept 2"],
    "en": ["Concept 1", "Concept 2"]
  },
  "vergleich": [
    {
      "konzept_de": "Aphrodite stehend",
      "konzept_en": "Aphrodite standing",
      "similarity": 95,
      "abweichung": false,
      "beschreibung": ""
    }
  ],
  "meta": {
    "source_id": 1234,
    "languages": ["de", "en"],
    "original_texts": {
      "de": "Vollst√§ndiger Originaltext Deutsch aus der Datenbank",
      "en": "Full original text English from database"
    },
    "execution_date": "2025-12-09T16:45:23.123456",
    "execution_time_seconds": 12.34
  }
}
```

**Metadaten:**
- `source_id`: ID aus der Datenbank
- `languages`: Verwendete Sprachen
- `original_texts`: Originaltexte aus field1/field2 (seit neuster Version)
- `execution_date`: Zeitstempel der Verarbeitung (ISO-Format)
- `execution_time_seconds`: Ausf√ºhrungszeit in Sekunden

### CSV-Export

Die exportierte CSV-Datei enth√§lt alle Vergleichseintr√§ge aus allen JSON-Dateien in tabellarischer Form. Ideal f√ºr:
- Analyse in Excel/LibreOffice
- Import in andere Systeme
- Statistische Auswertungen
- Schnelle √úbersicht √ºber Abweichungen

## Logging

- **Konsole**: Live-Output w√§hrend der Verarbeitung mit farbiger Kennzeichnung
- **Datei**: Vollst√§ndiges Log in `logs/processing.log`

Log-Level: INFO (Start/Ende, Erfolg/Fehler pro Datensatz)

### Farbige Terminal-Ausgabe

Die Terminal-Ausgabe nutzt Farben zur besseren √úbersichtlichkeit:

- üü¢ **Gr√ºn**: √úbersprungene Datens√§tze (wenn `--skip-existing` aktiv)
- üü° **Gelb**: API-Aufrufe und -Antworten
- üî¥ **Rot**: Fehler und fehlgeschlagene Versuche
- üîµ **Blau**: Zusammenfassungen und Statistiken
- üî∑ **Cyan**: Informationsmeldungen und Fortschritt

Zus√§tzlich wird jeder API-Aufruf mit einer fortlaufenden Nummer markiert: `[API #1]`, `[API #2]`, etc.

## Fehlerbehandlung

- **Netzwerkfehler**: Automatische Wiederholung mit konfigurierbarer Verz√∂gerung
- **Ung√ºltiges JSON**: Markdown-Code-Bl√∂cke werden automatisch entfernt, bei weiterem Fehler: Retry
- **Datenbankfehler**: Aussagekr√§ftige Fehlermeldungen
- **Einzelne Fehler**: Verarbeitung wird fortgesetzt, Fehler werden geloggt
- **CSV-Export**: Fehlende oder ung√ºltige JSON-Dateien werden √ºbersprungen

## Tipps & Best Practices

### Optimale Performance

- **LIMIT in Query**: Teste zuerst mit wenigen Datens√§tzen (z.B. `LIMIT 5`)
- **Timeout**: Erh√∂he `timeout_seconds` bei langsamen Modellen
- **Batch-Verarbeitung**: F√ºr gro√üe Datenmengen in mehreren Sessions
- **Zwei Sprachen**: Reduziert Nachdenkzeit der KI erheblich vs. drei Sprachen

### Workflow-Empfehlung

1. Teste mit 1-5 Datens√§tzen
2. Pr√ºfe JSON-Output auf Korrektheit
3. Exportiere CSV und validiere das Format
4. Bei Bedarf Prompt anpassen
5. Dann vollst√§ndige Verarbeitung starten (nutze `--skip-existing` bei Unterbrechungen)

### Inkrementelle Verarbeitung

Bei gro√üen Datenmengen empfiehlt sich folgendes Vorgehen:

1. **Erste Verarbeitung** mit kleinem LIMIT (z.B. 100 Datens√§tze)
   ```bash
   python src/main.py
   ```

2. **LIMIT erh√∂hen** in `config.yaml` (z.B. auf 500)

3. **Mit Skip-Modus fortsetzen** (verarbeitet nur neue IDs)
   ```bash
   python src/main.py --skip-existing
   ```

4. **Fehlgeschlagene IDs erneut verarbeiten**: L√∂sche deren JSON-Dateien und f√ºhre erneut mit `--skip-existing` aus

Dies spart API-Kosten und Zeit, da bereits verarbeitete Datens√§tze nicht erneut an die KI gesendet werden.

### Originaltexte nachtragen

Falls du bereits JSON-Dateien hast, die noch keine `original_texts` in den Metadaten enthalten:

```bash
python src/main.py --update-metadata
```

Dies:
- Liest alle Datens√§tze aus der Datenbank
- Aktualisiert nur die Metadaten in existierenden JSON-Dateien
- Macht **keine** API-Aufrufe (schnell und kostenfrei)
- √úberspringt IDs ohne JSON-Datei

Danach kannst du den CSV-Export neu ausf√ºhren, um die vollst√§ndigen Originaltexte in den Spalten zu haben.

### CSV-Export nutzen

Der CSV-Export ist ideal f√ºr:
- **Schnelle √úbersicht** √ºber alle Vergleiche
- **Analyse in Excel/LibreOffice** (Filter, Pivot-Tabellen)
- **Import in andere Systeme** (z.B. Datenbanken)
- **Statistische Auswertungen** (Similarity-Verteilung, Abweichungsrate)

## Anpassungen

### Andere Datenbanken

F√ºr MySQL:
```yaml
database:
  driver: "mysql+pymysql"
  # ... restliche Konfiguration
```

F√ºr SQLite:
```yaml
database:
  driver: "sqlite"
  name: "path/to/database.db"
  # host, port, user, password nicht ben√∂tigt
```

### API-Format anpassen

Falls deine OpenWebUI-Installation ein anderes Format erwartet, passe die Methoden in `openwebui_client.py` an:

- `build_payload()`: Request-Struktur
- `_extract_model_output()`: Response-Parsing

## Abh√§ngigkeiten

- **pyyaml**: YAML-Konfiguration
- **sqlalchemy**: Datenbank-Abstraktionsschicht
- **requests**: HTTP-Client f√ºr API-Aufrufe
- **psycopg2-binary**: PostgreSQL-Treiber

## Lizenz

[Deine Lizenz hier einf√ºgen]
