{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cdc8fa2",
   "metadata": {},
   "source": [
    "# Triple-Extraktor f√ºr fr√ºhneuzeitliche Briefe\n",
    "\n",
    "**Version:** 1.0.0.0\n",
    "\n",
    "Dieses Notebook extrahiert semantische Triples aus fr√ºhneuzeitlichen Briefen mit Fokus auf Konzept-Hierarchien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abh√§ngigkeiten installieren (einmal ausf√ºhren)\n",
    "!pip install -q plotly networkx kaleido numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup (einmal ausf√ºhren)\n",
    "# Installiert ben√∂tigte Pakete und l√§dt den Code.\n",
    "\n",
    "# Version\n",
    "NOTEBOOK_VERSION = \"1.0.0.0\"\n",
    "print(f\"üìì Triple-Extraktor Notebook v{NOTEBOOK_VERSION}\")\n",
    "print(f\"   Letzte Aktualisierung: 07.02.2026\\n\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Basisverzeichnis (JupyterHub/Standard-Jupyter)\n",
    "BASE_DIR = Path(\"./triple-jupyterhub\").resolve()\n",
    "SRC_DIR = BASE_DIR / \"src\"\n",
    "OUTPUT_JSON_DIR = BASE_DIR / \"output_json\"\n",
    "OUTPUT_PLAINTEXT_DIR = BASE_DIR / \"output_plaintext\"\n",
    "LOGS_DIR = BASE_DIR / \"logs\"\n",
    "UPLOADS_DIR = BASE_DIR / \"uploads\"\n",
    "GRAPHS_DIR = BASE_DIR / \"graphs\"\n",
    "\n",
    "for d in [SRC_DIR, OUTPUT_JSON_DIR, OUTPUT_PLAINTEXT_DIR, LOGS_DIR, UPLOADS_DIR, GRAPHS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Abh√§ngigkeiten pr√ºfen (Installation bitte √ºber Environment/requirements)\n",
    "missing = []\n",
    "try:\n",
    "    import yaml  # pyyaml\n",
    "except ImportError:\n",
    "    missing.append(\"pyyaml\")\n",
    "try:\n",
    "    import requests\n",
    "except ImportError:\n",
    "    missing.append(\"requests\")\n",
    "try:\n",
    "    import plotly\n",
    "except ImportError:\n",
    "    missing.append(\"plotly\")\n",
    "try:\n",
    "    import networkx\n",
    "except ImportError:\n",
    "    missing.append(\"networkx\")\n",
    "try:\n",
    "    import kaleido\n",
    "except ImportError:\n",
    "    missing.append(\"kaleido\")\n",
    "\n",
    "if missing:\n",
    "    print(\"‚ö† Fehlende Pakete:\", \", \".join(missing))\n",
    "    print(\"   Bitte installiere sie im JupyterHub-Environment (z.B. requirements.txt oder Admin-Setup).\")\n",
    "else:\n",
    "    print(\"‚úì Alle ben√∂tigten Pakete sind verf√ºgbar\")\n",
    "\n",
    "# Python-Path erweitern\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "# file_client.py erstellen\n",
    "file_client_code = '''\"\"\"Datei-Client f√ºr XML/TXT-Dateien mit TEI-Optimierung.\"\"\"\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import Optional, List\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class FileClient:\n",
    "    \"\"\"Client zum Lesen von XML/TXT-Dateien mit TEI-Optimierung.\"\"\"\n",
    "    \n",
    "    # Verarbeitungsmodus: 'plaintext', 'raw_xml', 'xml_to_plaintext'\n",
    "    processing_mode = 'xml_to_plaintext'\n",
    "    # Tags die komplett entfernt werden sollen (mit Inhalt)\n",
    "    exclude_tags = []\n",
    "    # Tag-Attribute-Kombinationen die entfernt werden sollen z.B. [('div', 'type', 'comment')]\n",
    "    exclude_tag_attrs = []\n",
    "    \n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = file_path\n",
    "        self.file_extension = os.path.splitext(file_path)[1].lower()\n",
    "    \n",
    "    def read_content(self) -> Optional[str]:\n",
    "        \"\"\"Liest den Dateiinhalt und extrahiert relevanten Text.\"\"\"\n",
    "        try:\n",
    "            if self.file_extension == \".xml\":\n",
    "                return self._read_xml()\n",
    "            elif self.file_extension == \".txt\":\n",
    "                return self._read_txt()\n",
    "            else:\n",
    "                logger.warning(f\"Nicht unterst√ºtztes Dateiformat: {self.file_extension}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Lesen von {self.file_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _read_xml(self) -> Optional[str]:\n",
    "        \"\"\"Liest XML-Datei basierend auf processing_mode.\"\"\"\n",
    "        # Modus: Raw XML - unverarbeitet zur√ºckgeben\n",
    "        if FileClient.processing_mode == 'raw_xml':\n",
    "            with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                return f.read()\n",
    "        \n",
    "        # XML parsen\n",
    "        try:\n",
    "            tree = ET.parse(self.file_path)\n",
    "            root = tree.getroot()\n",
    "        except ET.ParseError as e:\n",
    "            logger.error(f\"XML-Parse-Fehler in {self.file_path}: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # Modus: XML zu Plaintext konvertieren (mit Tag-Filterung)\n",
    "        namespaces = {\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "        \n",
    "        # Arbeite mit Kopie um Original nicht zu ver√§ndern\n",
    "        root_copy = copy.deepcopy(root)\n",
    "        \n",
    "        # Entferne ausgeschlossene Tags\n",
    "        self._remove_excluded_elements(root_copy, namespaces)\n",
    "        \n",
    "        # Body finden und Text extrahieren\n",
    "        body = root_copy.find(\".//tei:body\", namespaces)\n",
    "        if body is None:\n",
    "            body = root_copy.find(\".//body\")\n",
    "        if body is None:\n",
    "            body = root_copy\n",
    "        \n",
    "        return self._extract_text_from_element(body)\n",
    "    \n",
    "    def _remove_excluded_elements(self, root: ET.Element, namespaces: dict):\n",
    "        \"\"\"Entfernt ausgeschlossene Elemente aus dem XML-Baum.\"\"\"\n",
    "        # Entferne Tags mit bestimmten Attributen (z.B. div[@type='comment'])\n",
    "        for tag, attr_name, attr_value in FileClient.exclude_tag_attrs:\n",
    "            # Mit TEI-Namespace\n",
    "            for elem in root.findall(f\".//tei:{tag}[@{attr_name}]\", namespaces):\n",
    "                if attr_value in elem.get(attr_name, ''):\n",
    "                    parent = self._find_parent(root, elem)\n",
    "                    if parent is not None:\n",
    "                        # Tail-Text bewahren\n",
    "                        if elem.tail:\n",
    "                            prev = list(parent).index(elem)\n",
    "                            if prev > 0:\n",
    "                                list(parent)[prev-1].tail = (list(parent)[prev-1].tail or '') + elem.tail\n",
    "                            else:\n",
    "                                parent.text = (parent.text or '') + elem.tail\n",
    "                        parent.remove(elem)\n",
    "            # Ohne Namespace\n",
    "            for elem in root.findall(f\".//{tag}[@{attr_name}]\"):\n",
    "                if attr_value in elem.get(attr_name, ''):\n",
    "                    parent = self._find_parent(root, elem)\n",
    "                    if parent is not None:\n",
    "                        if elem.tail:\n",
    "                            prev = list(parent).index(elem)\n",
    "                            if prev > 0:\n",
    "                                list(parent)[prev-1].tail = (list(parent)[prev-1].tail or '') + elem.tail\n",
    "                            else:\n",
    "                                parent.text = (parent.text or '') + elem.tail\n",
    "                        parent.remove(elem)\n",
    "        \n",
    "        # Entferne komplette Tags (mit Inhalt)\n",
    "        for tag in FileClient.exclude_tags:\n",
    "            # Mit TEI-Namespace\n",
    "            for elem in root.findall(f\".//tei:{tag}\", namespaces):\n",
    "                parent = self._find_parent(root, elem)\n",
    "                if parent is not None:\n",
    "                    if elem.tail:\n",
    "                        prev = list(parent).index(elem)\n",
    "                        if prev > 0:\n",
    "                            list(parent)[prev-1].tail = (list(parent)[prev-1].tail or '') + elem.tail\n",
    "                        else:\n",
    "                            parent.text = (parent.text or '') + elem.tail\n",
    "                    parent.remove(elem)\n",
    "            # Ohne Namespace\n",
    "            for elem in root.findall(f\".//{tag}\"):\n",
    "                parent = self._find_parent(root, elem)\n",
    "                if parent is not None:\n",
    "                    if elem.tail:\n",
    "                        prev = list(parent).index(elem)\n",
    "                        if prev > 0:\n",
    "                            list(parent)[prev-1].tail = (list(parent)[prev-1].tail or '') + elem.tail\n",
    "                        else:\n",
    "                            parent.text = (parent.text or '') + elem.tail\n",
    "                    parent.remove(elem)\n",
    "    \n",
    "    def _find_parent(self, root: ET.Element, target: ET.Element) -> Optional[ET.Element]:\n",
    "        \"\"\"Findet das Elternelement eines Elements.\"\"\"\n",
    "        for parent in root.iter():\n",
    "            for child in parent:\n",
    "                if child is target:\n",
    "                    return parent\n",
    "        return None\n",
    "    \n",
    "    def _read_txt(self) -> Optional[str]:\n",
    "        \"\"\"Liest TXT-Datei.\"\"\"\n",
    "        with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    \n",
    "    def _extract_text_from_element(self, element) -> str:\n",
    "        \"\"\"Extrahiert rekursiv Text aus XML-Element.\"\"\"\n",
    "        texts = []\n",
    "        if element.text:\n",
    "            texts.append(element.text.strip())\n",
    "        for child in element:\n",
    "            texts.append(self._extract_text_from_element(child))\n",
    "            if child.tail:\n",
    "                texts.append(child.tail.strip())\n",
    "        result = \" \".join(filter(None, texts))\n",
    "        # Bereinige mehrfache Leerzeichen\n",
    "        result = re.sub(r'\\\\s+', ' ', result)\n",
    "        return result.strip()\n",
    "'''\n",
    "\n",
    "with open(SRC_DIR / 'file_client.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(file_client_code)\n",
    "\n",
    "# openwebui_client.py erstellen\n",
    "openwebui_client_code = '''\"\"\"OpenWebUI-kompatibler Client mit Gemini/OpenAI-Support.\"\"\"\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class OpenWebUIClient:\n",
    "    \"\"\"Client f√ºr OpenAI-kompatible APIs (inkl. Gemini).\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, base_url: str, model: str, temperature: float = 0.1):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.max_retries = 3\n",
    "        self.retry_delay = 2\n",
    "    \n",
    "    def generate_response(self, prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:\n",
    "        \"\"\"Generiert Antwort mit automatischem Retry.\"\"\"\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                if \"generativelanguage.googleapis.com\" in self.base_url:\n",
    "                    return self._call_gemini_api(prompt, system_prompt)\n",
    "                else:\n",
    "                    return self._call_openai_api(prompt, system_prompt)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Versuch {attempt + 1}/{self.max_retries} fehlgeschlagen: {e}\")\n",
    "                if attempt < self.max_retries - 1:\n",
    "                    time.sleep(self.retry_delay * (attempt + 1))\n",
    "                else:\n",
    "                    logger.error(f\"Alle Versuche fehlgeschlagen: {e}\")\n",
    "                    return None\n",
    "    \n",
    "    def _call_gemini_api(self, prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:\n",
    "        \"\"\"Ruft Gemini API auf.\"\"\"\n",
    "        url = f\"{self.base_url}:generateContent?key={self.api_key}\"\n",
    "        payload = {\n",
    "            \"contents\": [{\"parts\": [{\"text\": prompt}]}],\n",
    "            \"generationConfig\": {\"temperature\": self.temperature}\n",
    "        }\n",
    "        if system_prompt:\n",
    "            payload[\"systemInstruction\"] = {\"parts\": [{\"text\": system_prompt}]}\n",
    "        response = requests.post(url, json=payload, timeout=120)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "    \n",
    "    def _call_openai_api(self, prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:\n",
    "        \"\"\"Ruft OpenAI-kompatible API auf.\"\"\"\n",
    "        url = f\"{self.base_url}/chat/completions\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        messages = []\n",
    "        if system_prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": self.temperature\n",
    "        }\n",
    "        response = requests.post(url, headers=headers, json=payload, timeout=120)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "'''\n",
    "\n",
    "with open(SRC_DIR / 'openwebui_client.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(openwebui_client_code)\n",
    "\n",
    "print(\"‚úì Setup abgeschlossen!\")\n",
    "print(f\"‚úì Arbeitsverzeichnis: {BASE_DIR}\")\n",
    "print(\"‚úì Code-Module erstellt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f367c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API-Konfiguration\n",
    "#\n",
    "## Eingaben unten anpassen (API-Provider, Key, Modell, Parameter).\n",
    "\n",
    "# W√§hle deinen API-Provider:\n",
    "api_provider = \"Gemini (Google)\"  # Eingabe: \"Gemini (Google)\" oder \"ChatAI (AcademicCloud)\"\n",
    "\n",
    "# API-Schl√ºssel:\n",
    "# Wichtig: niemals in √∂ffentlichen Notebooks teilen!\n",
    "api_key = \"\"  # Eingabe: API-Key hier einf√ºgen\n",
    "\n",
    "# Modell-Auswahl:\n",
    "# Verf√ºgbare Modelle (Anzeigename ‚Üí Provider):\n",
    "# - gemini-3-flash-preview (Gemini Standard) ‚Üí Gemini (Google)\n",
    "# - gemini-2.5-flash (Gemini) ‚Üí Gemini (Google)\n",
    "# - llama-3.3-70b-instruct (ChatAI) ‚Üí ChatAI (AcademicCloud)\n",
    "selected_model_name = \"gemini-3-flash-preview (Gemini Standard)\"  # Eingabe: Modellname aus der Liste\n",
    "\n",
    "# Detailgrad der Extraktion:\n",
    "granularity = 3  # Eingabe: 1 (kurz) bis 10 (sehr detailliert)\n",
    "\n",
    "# Temperatur (Kreativit√§t):\n",
    "temperature = 0.3  # Eingabe: 0.0 (deterministisch) bis 1.0 (kreativ)\n",
    "\n",
    "# Erweiterte Optionen:\n",
    "show_debug_output = False  # Eingabe: True zeigt Debug-Ausgaben bei Fehlern\n",
    "\n",
    "# Metadaten werden IMMER gespeichert\n",
    "save_file_metadata = True\n",
    "\n",
    "# Modell-Mapping\n",
    "model_mapping = {\n",
    "    \"gemini-3-flash-preview (Gemini Standard)\": {\n",
    "        \"name\": \"gemini-3-flash-preview\",\n",
    "        \"provider\": \"Gemini (Google)\"\n",
    "    },\n",
    "    \"gemini-2.5-flash (Gemini)\": {\n",
    "        \"name\": \"gemini-2.5-flash\",\n",
    "        \"provider\": \"Gemini (Google)\"\n",
    "    },\n",
    "    \"llama-3.3-70b-instruct (ChatAI)\": {\n",
    "        \"name\": \"llama-3.3-70b-instruct\",\n",
    "        \"provider\": \"ChatAI (AcademicCloud)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Modell-Info extrahieren\n",
    "model_info = model_mapping.get(selected_model_name)\n",
    "if not model_info:\n",
    "    raise ValueError(f\"Unbekanntes Modell: {selected_model_name}\")\n",
    "\n",
    "selected_model = model_info[\"name\"]\n",
    "model_provider = model_info[\"provider\"]\n",
    "\n",
    "# Pr√ºfe ob Modell zum gew√§hlten Provider passt\n",
    "if model_provider != api_provider:\n",
    "    raise ValueError(\n",
    "        f\"‚ùå Modell-Provider-Konflikt!\\n\\n\"\n",
    "        f\"Das gew√§hlte Modell '{selected_model}' geh√∂rt zu '{model_provider}',\\n\"\n",
    "        f\"aber du hast '{api_provider}' als Provider ausgew√§hlt.\\n\\n\"\n",
    "        f\"Bitte w√§hle entweder:\\n\"\n",
    "        f\"‚Ä¢ Ein Modell das zu '{api_provider}' passt, oder\\n\"\n",
    "        f\"‚Ä¢ √Ñndere den Provider auf '{model_provider}'\"\n",
    "    )\n",
    "\n",
    "# API-Schl√ºssel validieren\n",
    "if not api_key or len(api_key.strip()) < 10:\n",
    "    raise ValueError(\n",
    "        \"‚ùå Ung√ºltiger API-Schl√ºssel!\\n\\n\"\n",
    "        \"Bitte gib einen g√ºltigen API-Schl√ºssel ein.\\n\\n\"\n",
    "        \"API-Schl√ºssel erhalten:\\n\"\n",
    "        \"‚Ä¢ Gemini: https://aistudio.google.com/apikey\\n\"\n",
    "        \"‚Ä¢ ChatAI: https://chat-ai.academiccloud.de/\"\n",
    "    )\n",
    "\n",
    "# Konfiguration basierend auf Provider\n",
    "if api_provider == \"Gemini (Google)\":\n",
    "    base_url = f\"https://generativelanguage.googleapis.com/v1beta/models/{selected_model}\"\n",
    "else:  # ChatAI\n",
    "    base_url = \"https://chat-ai.academiccloud.de/v1\"\n",
    "\n",
    "# Konfiguration speichern\n",
    "selected_config = {\n",
    "    'provider': api_provider,\n",
    "    'api_key': api_key,\n",
    "    'base_url': base_url,\n",
    "    'model': selected_model,\n",
    "    'temperature': temperature,\n",
    "    'granularity': granularity,\n",
    "    'include_metadata': save_file_metadata,\n",
    "    'verbose': show_debug_output\n",
    "}\n",
    "\n",
    "print(f\"‚úì Konfiguration gespeichert\")\n",
    "print(f\"  Provider: {api_provider}\")\n",
    "print(f\"  Modell: {selected_model}\")\n",
    "print(f\"  Detailgrad: {granularity}\")\n",
    "print(f\"  Temperatur: {temperature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML-Verarbeitungsoptionen\n",
    "#\n",
    "## Eingaben unten anpassen (Modus, ausgeschlossene Tags/Attribute).\n",
    "\n",
    "# Verarbeitungsmodus:\n",
    "xml_processing_mode = \"XML zu Plaintext (empfohlen)\"  # Eingabe: \"Plaintext (nur .txt)\", \"XML unverarbeitet\", \"XML zu Plaintext (empfohlen)\"\n",
    "\n",
    "# Tags komplett entfernen (mit Inhalt):\n",
    "exclude_tags_input = \"postscript\"  # Eingabe: Komma-getrennte Liste, z.B. \"postscript, note, anchor\"\n",
    "\n",
    "# Tags mit bestimmten Attributen entfernen:\n",
    "exclude_attrs_input = \"div:type=comment\"  # Eingabe: \"tag:attribut=wert\", z.B. \"div:type=comment, div:type=apparatus\"\n",
    "\n",
    "from file_client import FileClient\n",
    "\n",
    "# Modus setzen\n",
    "mode_map = {\n",
    "    \"Plaintext (nur .txt)\": \"plaintext\",\n",
    "    \"XML unverarbeitet\": \"raw_xml\",\n",
    "    \"XML zu Plaintext (empfohlen)\": \"xml_to_plaintext\"\n",
    "}\n",
    "FileClient.processing_mode = mode_map.get(xml_processing_mode, \"xml_to_plaintext\")\n",
    "\n",
    "# Ausgeschlossene Tags parsen\n",
    "if exclude_tags_input.strip():\n",
    "    FileClient.exclude_tags = [t.strip() for t in exclude_tags_input.split(',') if t.strip()]\n",
    "else:\n",
    "    FileClient.exclude_tags = []\n",
    "\n",
    "# Ausgeschlossene Tag-Attribute parsen (Format: tag:attr=value)\n",
    "FileClient.exclude_tag_attrs = []\n",
    "if exclude_attrs_input.strip():\n",
    "    for item in exclude_attrs_input.split(','):\n",
    "        item = item.strip()\n",
    "        if ':' in item and '=' in item:\n",
    "            tag_part, attr_part = item.split(':', 1)\n",
    "            if '=' in attr_part:\n",
    "                attr_name, attr_value = attr_part.split('=', 1)\n",
    "                FileClient.exclude_tag_attrs.append((tag_part.strip(), attr_name.strip(), attr_value.strip()))\n",
    "\n",
    "print(f\"‚úì XML-Verarbeitung konfiguriert\")\n",
    "print(f\"  Modus: {xml_processing_mode}\")\n",
    "if FileClient.exclude_tags:\n",
    "    print(f\"  Entfernte Tags: {', '.join(FileClient.exclude_tags)}\")\n",
    "if FileClient.exclude_tag_attrs:\n",
    "    attrs_str = ', '.join([f\"<{t}[@{a}='{v}']>\" for t, a, v in FileClient.exclude_tag_attrs])\n",
    "    print(f\"  Entfernte Elemente: {attrs_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d7a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System-Prompt bearbeiten (optional)\n",
    "#\n",
    "## Eingabe: Setze True, um einen eigenen Prompt zu verwenden.\n",
    "\n",
    "use_custom_prompt = False  # Eingabe: True/False\n",
    "\n",
    "# Optional: eigenen Prompt hier einf√ºgen (leer = Default-Prompt)\n",
    "CUSTOM_PROMPT_OVERRIDE = \"\"  # Eingabe: eigenen Prompt hier einf√ºgen\n",
    "\n",
    "# Default-Prompt\n",
    "DEFAULT_PROMPT = \"\"\"# Prompt: Extraktion semantischer Triples aus fr√ºhneuzeitlichen Briefen  \n",
    "**(LLM-optimiert, strikt themenzentriert, konzept-hierarchisch, nicht redundant)**\n",
    "\n",
    "Du bist ein Experte f√ºr fr√ºhneuzeitliche Korrespondenz im **mitteleurop√§ischen Raum des sp√§ten 18. und fr√ºhen 19. Jahrhunderts (ca. 1750‚Äì1809)**.  \n",
    "Deine Aufgabe ist die Extraktion **kanonischer, nicht redundanter** semantischer Triples  \n",
    "(**Subjekt ‚Äì Pr√§dikat ‚Äì Objekt**) aus historischen Briefen dieses Zeitraums.\n",
    "\n",
    "Der **historische Hintergrund Mitteleuropas** (Bildungswesen, Konfessionen, soziale Ordnung, Elternautorit√§t, Universit√§tskultur, Ehr- und Reputationsnormen, Briefkultur) ist **stillschweigend zu ber√ºcksichtigen**, ohne anachronistische Begriffe oder moderne Konzepte einzuf√ºhren.\n",
    "\n",
    "Ziel ist ein **semantisch dichtes, stabiles, themenvergleichbares Ergebnis**, das sich f√ºr LLMs, Wissensgraphen und vergleichende Analysen eignet.\n",
    "\n",
    "---\n",
    "\n",
    "## INPUT\n",
    "Du erh√§ltst:\n",
    "- `abstraktionslevel` (1‚Äì5)\n",
    "- `brieftext` (vollst√§ndiger Text inkl. Briefkopf)\n",
    "- TEI-XML, ignoriere den TEI-header\n",
    "- ignoriere die Kommentare\n",
    "- ignoriere die Editorial Notes\n",
    "\n",
    "---\n",
    "\n",
    "## OUTPUT (VERBINDLICH)\n",
    "Gib **ausschlie√ülich reines JSON** aus:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"entities\": {...},\n",
    "  \"praedikate\": {...},\n",
    "  \"triples\": [...],\n",
    "  \"parameter\": {...}\n",
    "}\n",
    "```\n",
    "\n",
    "Keine Erkl√§rungen, kein Markdown, keine Zusatzfelder.\n",
    "\n",
    "---\n",
    "\n",
    "## VERBINDLICHE NAMENSNORMALISIERUNG\n",
    "\n",
    "Die folgenden historischen oder vollst√§ndigen Namensformen sind **immer** auf die kanonische Form zu normalisieren:\n",
    "\n",
    "- Johann Paul Friedrich Richter ‚Üí Jean Paul  \n",
    "- Johann Wolfgang von G√∂the ‚Üí Goethe  \n",
    "- Gotthold Ephraim Lessing ‚Üí Lessing  \n",
    "- Immanuel Kant ‚Üí Kant  \n",
    "- Friedrich Schiller ‚Üí Schiller  \n",
    "\n",
    "Weitere Varianten sind **analog zu vereinheitlichen**  \n",
    "(b√ºrgerlicher Vollname ‚Üí etablierter Werkname).\n",
    "\n",
    "---\n",
    "\n",
    "## ABSTRAKTIONSLEVEL ‚Üí ZIELANZAHL TRIPLES\n",
    "\n",
    "| Level | Ziel |\n",
    "|------|------|\n",
    "| 1 | 1‚Äì2 Triples ‚Äì Kernaussage |\n",
    "| 2 | 3‚Äì5 Triples ‚Äì Kernaussage + Hauptthemen |\n",
    "| 3 | 8‚Äì12 Triples ‚Äì Themen + Argumentstruktur |\n",
    "| 4 | 12‚Äì20 Triples ‚Äì thematisch relevante Details |\n",
    "| 5 | 25+ Triples ‚Äì implizite, klar ableitbare Bedeutungen |\n",
    "\n",
    "---\n",
    "\n",
    "## KERNPRINZIP: KONZEPT-HIERARCHIE STATT AKTEURS-GRAPH\n",
    "\n",
    "Der Brief ist **prim√§r als thematisches System** zu modellieren, nicht als Abfolge von Handlungen oder Personen.\n",
    "\n",
    "### VERBINDLICHER MODELLIERUNGSPFAD\n",
    "\n",
    "#### 1. OBERKONZEPTE IDENTIFIZIEREN  \n",
    "Identifiziere zuerst **√ºbergeordnete Themenfelder** (Oberkonzepte), z.B.:\n",
    "\n",
    "- Emotion  \n",
    "- Krankheit  \n",
    "- Liebe  \n",
    "- Freundschaft  \n",
    "- Soziale Ordnung  \n",
    "- Moral / Gewissen  \n",
    "- Bildung  \n",
    "- Lebensweg  \n",
    "- Zukunft / Erwartung  \n",
    "\n",
    "Diese werden als **Konzept-Entit√§ten (Typ: Konzept)** modelliert.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. SUBKONZEPTE ABLEITEN  \n",
    "Leite daraus **inhaltlich unterscheidbare Unterthemen** ab.\n",
    "\n",
    "Beispiele:\n",
    "- Emotion ‚Üí Schwermut, Angst, Hoffnung  \n",
    "- Krankheit ‚Üí Hypochondrie, k√∂rperliche Schw√§che  \n",
    "- Soziale Ordnung ‚Üí elterliche Autorit√§t, soziale Kontrolle, Ruf  \n",
    "\n",
    "Subkonzepte sind **immer Konzepte, niemals Personenattribute**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. KONZEPT‚ÄìKONZEPT-BEZIEHUNGEN MODELLIEREN  \n",
    "Modelliere bevorzugt Beziehungen **zwischen Ober- und Subkonzepten** oder zwischen Subkonzepten.\n",
    "\n",
    "Beispiele:\n",
    "- Schwermut ist_Subkonzept_von Emotion  \n",
    "- Hypochondrie ist_Subkonzept_von Krankheit  \n",
    "- Soziale_Kontrolle versch√§rft Emotionale_Krise  \n",
    "- Krankheit beeinflusst Lebenswille  \n",
    "\n",
    "**Mindestens 50 % aller Triples m√ºssen Konzept‚ÜîKonzept sein.**\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. PERSONEN NUR ALS TR√ÑGER (NACHRANGIG)\n",
    "Personen d√ºrfen **nur** erscheinen, wenn sie:\n",
    "- Tr√§ger eines Konzepts sind\n",
    "- von einem Konzept betroffen sind\n",
    "- eine thematische Dynamik ausl√∂sen\n",
    "\n",
    "Zul√§ssige Muster:\n",
    "- Krankheit betrifft Wagner  \n",
    "- Emotionale_Krise betrifft Empf√§nger  \n",
    "\n",
    "Unzul√§ssig:\n",
    "- Person ‚Üî Person ohne thematische Vermittlung\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. ORTE NUR ALS THEMATISCHER RAHMEN (AUSNAHME)\n",
    "Orte d√ºrfen nur modelliert werden, wenn sie:\n",
    "- einen thematischen Zustand rahmen oder beeinflussen\n",
    "- sozial oder symbolisch relevant sind\n",
    "\n",
    "Unzul√§ssig:\n",
    "- reine Lokalisierungen (‚Äûschreibt aus X\")\n",
    "\n",
    "---\n",
    "\n",
    "## AUFL√ñSUNG VON ZUSTANDS-, ROLLEN- UND KOMPOSIT-ENTIT√ÑTEN\n",
    "\n",
    "Komplexe Zuschreibungen wie  \n",
    "‚ÄûX-Zustand von Person Y\"  \n",
    "d√ºrfen **nicht** als eigene Entit√§t stehen bleiben.\n",
    "\n",
    "Sie sind **immer** zu zerlegen in:\n",
    "1. ein **abstraktes Konzept**\n",
    "2. eine **explizite Beziehung**\n",
    "\n",
    "Beispiel:\n",
    "- ‚ÄûKrankheitszustand Wagners\"  \n",
    "  ‚Üí Konzept: Krankheit  \n",
    "  ‚Üí Triple: Krankheit betrifft Wagner\n",
    "\n",
    "---\n",
    "\n",
    "## REDUNDANZ-REGELN (STRIKT)\n",
    "\n",
    "1. Keine Dubletten  \n",
    "2. Keine Spiegelungen ohne Mehrwert  \n",
    "3. Keine leeren Kommunikations-Triples  \n",
    "4. Komplexe Sachverhalte als Ereignisknoten  \n",
    "5. Verdichten statt auflisten  \n",
    "\n",
    "---\n",
    "\n",
    "## ENTIT√ÑTEN\n",
    "\n",
    "**Typen**:  \n",
    "Person | Ort | Werk | Institution | Ereignis | Konzept | Zeitpunkt | Sonstiges  \n",
    "\n",
    "**Normalisierung**:\n",
    "- ‚Äûich\" ‚Üí Absender\n",
    "- ‚ÄûSie\" ‚Üí Empf√§nger\n",
    "- moderne Rechtschreibung\n",
    "- vollst√§ndige Datumsangaben\n",
    "- historische Ortsnamen beibehalten\n",
    "\n",
    "**IDs**: E1, E2, E3, ‚Ä¶\n",
    "\n",
    "---\n",
    "\n",
    "## PR√ÑDIKATE\n",
    "\n",
    "Verwende ein **kleines, stabiles Pr√§dikatsinventar**  \n",
    "(Level 3: ca. 10‚Äì16 Pr√§dikate).\n",
    "\n",
    "Beispiele:\n",
    "- ist_Subkonzept_von\n",
    "- beeinflusst\n",
    "- versch√§rft\n",
    "- beruhigt\n",
    "- reguliert\n",
    "- verursacht\n",
    "- interpretiert_als\n",
    "- betrifft\n",
    "- unterliegt\n",
    "- rahmt\n",
    "- empfiehlt\n",
    "\n",
    "---\n",
    "\n",
    "## JSON-FORMAT (VERBINDLICH)\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"entities\": {\n",
    "    \"E1\": {\"label\": \"...\", \"typ\": \"...\"}\n",
    "  },\n",
    "  \"praedikate\": {\n",
    "    \"P1\": {\"label\": \"...\", \"normalisiert_von\": [\"...\"]}\n",
    "  },\n",
    "  \"triples\": [\n",
    "    {\"subjekt\": \"E1\", \"praedikat\": \"P1\", \"objekt\": \"E2\"}\n",
    "  ],\n",
    "  \"parameter\": {\n",
    "    \"granularitaet\": 3,\n",
    "    \"anzahl_triples\": 10\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## START\n",
    "Analysiere nun den bereitgestellten `brieftext` gem√§√ü diesen Regeln  \n",
    "und gib **ausschlie√ülich das JSON** aus.\"\"\"\n",
    "\n",
    "if use_custom_prompt:\n",
    "    CUSTOM_PROMPT = CUSTOM_PROMPT_OVERRIDE.strip() or DEFAULT_PROMPT\n",
    "    if CUSTOM_PROMPT_OVERRIDE.strip():\n",
    "        print(\"‚úì Eigener Prompt aktiviert\")\n",
    "    else:\n",
    "        print(\"‚Ñπ Eigener Prompt aktiviert, aber leer ‚Äì Default-Prompt wird verwendet\")\n",
    "else:\n",
    "    CUSTOM_PROMPT = None\n",
    "    print(\"‚Ñπ Standard-Prompt wird verwendet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f6f8cc",
   "metadata": {},
   "source": [
    "## Dateien manuell hochladen (ohne Widgets)\n",
    "\n",
    "1. √ñffne im Jupyter-Dateibrowser den Ordner `triple-jupyterhub/uploads`.\n",
    "2. Lade deine Dateien dort hoch (.xml oder .zip).\n",
    "3. Wenn du ZIPs hochl√§dst, werden sie in der n√§chsten Zelle automatisch entpackt.\n",
    "4. F√ºhre danach die n√§chste Zelle ‚ÄûDateien vorbereiten‚Äú aus, um die Dateien zu scannen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88338e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dateien vorbereiten (ohne Widgets)\n",
    "#\n",
    "## Eingabe: Dateien manuell in den Ordner `triple-jupyterhub/uploads` legen, dann Zelle ausf√ºhren.\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Upload-Verzeichnis\n",
    "base_dir = Path(globals().get(\"BASE_DIR\", Path(\"./triple-jupyterhub\").resolve()))\n",
    "upload_dir = base_dir / \"uploads\"\n",
    "upload_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Globale Variable f√ºr Dateiliste\n",
    "if 'uploaded_files' not in globals():\n",
    "    uploaded_files = []\n",
    "\n",
    "def reset_all():\n",
    "    \"\"\"Setzt alles zur√ºck au√üer API-Konfiguration.\"\"\"\n",
    "    global uploaded_files, results, current_graph_index\n",
    "    \n",
    "    # L√∂sche Upload-Verzeichnis\n",
    "    if upload_dir.exists():\n",
    "        shutil.rmtree(upload_dir)\n",
    "    upload_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # L√∂sche Ergebnisse\n",
    "    output_dir = base_dir / \"output_json\"\n",
    "    if output_dir.exists():\n",
    "        for file in output_dir.iterdir():\n",
    "            if file.is_file():\n",
    "                file.unlink()\n",
    "    \n",
    "    graphs_dir = base_dir / \"graphs\"\n",
    "    if graphs_dir.exists():\n",
    "        shutil.rmtree(graphs_dir)\n",
    "    graphs_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Variablen zur√ºcksetzen\n",
    "    uploaded_files = []\n",
    "    results = []\n",
    "    current_graph_index = 0\n",
    "    \n",
    "    print(\"‚úì Alle Dateien und Ergebnisse gel√∂scht - API-Konfiguration bleibt erhalten\")\n",
    "\n",
    "def safe_extract_zipfile(zip_path: Path, target_dir: Path):\n",
    "    \"\"\"Sichere ZIP-Extraktion (verhindert Path Traversal).\"\"\"\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        for member in zip_ref.infolist():\n",
    "            member_path = target_dir / member.filename\n",
    "            target_path = member_path.resolve()\n",
    "            base_path = target_dir.resolve()\n",
    "            if not str(target_path).startswith(str(base_path) + os.sep) and target_path != base_path:\n",
    "                raise ValueError(f\"Unsichere Pfadangabe im ZIP-Archiv erkannt: {member.filename}\")\n",
    "        zip_ref.extractall(target_dir)\n",
    "\n",
    "def extract_any_zips():\n",
    "    \"\"\"Entpackt ZIP-Dateien im Upload-Ordner.\"\"\"\n",
    "    for zip_path in upload_dir.rglob('*.zip'):\n",
    "        print(f\"üì¶ Entpacke {zip_path.name}...\")\n",
    "        safe_extract_zipfile(zip_path, upload_dir)\n",
    "        zip_path.unlink(missing_ok=True)\n",
    "        print(f\"‚úì {zip_path.name} erfolgreich entpackt\")\n",
    "\n",
    "def scan_upload_folder():\n",
    "    \"\"\"Scanne Upload-Ordner nach XML-Dateien.\"\"\"\n",
    "    global uploaded_files\n",
    "    extract_any_zips()\n",
    "    uploaded_files = [str(p) for p in upload_dir.rglob('*.xml')]\n",
    "    if not uploaded_files:\n",
    "        print(\"Keine Dateien hochgeladen.\")\n",
    "    else:\n",
    "        print(f\"‚úì {len(uploaded_files)} XML-Datei(en):\\n\")\n",
    "        for i, filepath in enumerate(uploaded_files, 1):\n",
    "            print(f\"  {i}. {Path(filepath).name}\")\n",
    "    return uploaded_files\n",
    "\n",
    "# Initialer Scan\n",
    "scan_upload_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f1c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verarbeitung starten\n",
    "#\n",
    "## Voraussetzung: API-Konfiguration und Dateiupload abgeschlossen.\n",
    "\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from file_client import FileClient\n",
    "from openwebui_client import OpenWebUIClient\n",
    "\n",
    "# Validierung\n",
    "if 'selected_config' not in globals():\n",
    "    raise ValueError(\n",
    "        \"‚ùå Keine API-Konfiguration gefunden!\\n\\n\"\n",
    "        \"Bitte f√ºhre zuerst die Zelle 'API-Konfiguration' aus.\"\n",
    "    )\n",
    "\n",
    "if 'api_key' not in globals() or not api_key:\n",
    "    raise ValueError(\n",
    "        \"‚ùå Kein API-Schl√ºssel gefunden!\\n\\n\"\n",
    "        \"Bitte f√ºhre die Zelle 'API-Konfiguration' aus und gib deinen API-Schl√ºssel ein.\"\n",
    "    )\n",
    "\n",
    "if 'uploaded_files' not in globals() or not uploaded_files:\n",
    "    raise ValueError(\n",
    "        \"‚ùå Keine Dateien hochgeladen!\\n\\n\"\n",
    "        \"Bitte f√ºhre zuerst die Zelle 'Dateien hochladen' aus.\"\n",
    "    )\n",
    "\n",
    "# Client initialisieren\n",
    "client = OpenWebUIClient(\n",
    "    api_key=selected_config['api_key'],\n",
    "    base_url=selected_config['base_url'],\n",
    "    model=selected_config['model'],\n",
    "    temperature=selected_config['temperature']\n",
    " )\n",
    "\n",
    "# System-Prompt - IMMER den DEFAULT_PROMPT verwenden, bei Custom den bearbeiteten\n",
    "system_prompt = CUSTOM_PROMPT if ('use_custom_prompt' in globals() and use_custom_prompt and CUSTOM_PROMPT) else DEFAULT_PROMPT\n",
    "\n",
    "# Prompt-Template (vereinfacht, Hauptinstruktionen sind im System-Prompt)\n",
    "def create_prompt(text, granularity):\n",
    "    return f\"\"\"Abstraktionslevel: {granularity}\n",
    "\n",
    "Brieftext:\n",
    "{text}\"\"\"\n",
    "\n",
    "# Verzeichnisse\n",
    "base_dir = Path(globals().get(\"BASE_DIR\", Path(\"./triple-jupyterhub\").resolve()))\n",
    "output_dir = base_dir / \"output_json\"\n",
    "plaintext_dir = base_dir / \"output_plaintext\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "plaintext_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Verarbeitung\n",
    "results = []\n",
    "\n",
    "print(f\"Verarbeite {len(uploaded_files)} Datei(en)...\\n\")\n",
    "\n",
    "for i, filepath in enumerate(uploaded_files, 1):\n",
    "    filename = os.path.basename(filepath)\n",
    "    print(f\"[{i}/{len(uploaded_files)}] {filename}\")\n",
    "    \n",
    "    try:\n",
    "        # Zeitmessung starten\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Text einlesen\n",
    "        file_client = FileClient(filepath)\n",
    "        text = file_client.read_content()\n",
    "        \n",
    "        if not text:\n",
    "            print(f\"  ‚ö† Konnte Text nicht extrahieren\")\n",
    "            continue\n",
    "        \n",
    "        # Zeichenanzahl ermitteln\n",
    "        char_count = len(text)\n",
    "        \n",
    "        # Plaintext-Datei speichern\n",
    "        plaintext_filename = os.path.splitext(filename)[0] + '.txt'\n",
    "        plaintext_path = plaintext_dir / plaintext_filename\n",
    "        with open(plaintext_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "        \n",
    "        # API-Anfrage\n",
    "        prompt = create_prompt(text, selected_config['granularity'])\n",
    "        response = client.generate_response(prompt, system_prompt)\n",
    "        \n",
    "        if not response:\n",
    "            print(f\"  ‚ùå Keine Antwort erhalten\")\n",
    "            continue\n",
    "        \n",
    "        # JSON parsen\n",
    "        try:\n",
    "            clean_response = response.strip()\n",
    "            if clean_response.startswith('```'):\n",
    "                clean_response = '\\n'.join(clean_response.split('\\n')[1:-1])\n",
    "            if clean_response.startswith('json'):\n",
    "                clean_response = '\\n'.join(clean_response.split('\\n')[1:])\n",
    "            \n",
    "            data = json.loads(clean_response)\n",
    "            triple_count = len(data.get('triples', []))\n",
    "            \n",
    "            # Zeitmessung beenden\n",
    "            end_time = time.time()\n",
    "            execution_time = round(end_time - start_time, 2)\n",
    "            \n",
    "            # Metadaten im Pipeline-Format hinzuf√ºgen\n",
    "            data['metadata'] = {\n",
    "                'datei': os.path.splitext(filename)[0],\n",
    "                'verarbeitet': datetime.now().isoformat(),\n",
    "                'ausfuehrungszeit_sekunden': execution_time,\n",
    "                'modell': selected_config['model'],\n",
    "                'api_provider': selected_config['provider'],\n",
    "                'zeichenanzahl': char_count,\n",
    "                'original_text': text\n",
    "            }\n",
    "            \n",
    "            # Ergebnis speichern\n",
    "            output_filename = os.path.splitext(filename)[0] + '.json'\n",
    "            output_path = output_dir / output_filename\n",
    "            \n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            results.append({\n",
    "                'filename': filename,\n",
    "                'triples': data.get('triples', []),\n",
    "                'entities': data.get('entities', {}),\n",
    "                'praedikate': data.get('praedikate', {}),\n",
    "                'output_path': str(output_path),\n",
    "                'plaintext_path': str(plaintext_path)\n",
    "            })\n",
    "            \n",
    "            print(f\"  ‚úì {triple_count} Triples extrahiert ({execution_time}s)\")\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"  ‚ùå JSON-Parse-Fehler: {e}\")\n",
    "            if selected_config.get('verbose', False):\n",
    "                print(f\"  Response: {response[:200]}...\")\n",
    "            continue\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Fehler: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n‚úì Verarbeitung abgeschlossen!\")\n",
    "print(f\"  {len(results)} von {len(uploaded_files)} Dateien erfolgreich verarbeitet\")\n",
    "total_triples = sum(len(r['triples']) for r in results)\n",
    "print(f\"  {total_triples} Triples gesamt extrahiert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf617d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnis visualisieren (ohne Chrome-Abh√§ngigkeit)\n",
    "#\n",
    "## Voraussetzung: Verarbeitung abgeschlossen.\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "if 'results' not in globals() or not results:\n",
    "    print(\"‚ùå Keine Ergebnisse vorhanden. Bitte f√ºhre zuerst die Verarbeitung aus.\")\n",
    "else:\n",
    "    # Graphs-Verzeichnis erstellen\n",
    "    base_dir = Path(globals().get(\"BASE_DIR\", Path(\"./triple-jupyterhub\").resolve()))\n",
    "    graphs_dir = base_dir / \"graphs\"\n",
    "    graphs_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Eingabe: Index der Datei, die angezeigt werden soll\n",
    "    graph_index = 0  # Eingabe: 0 bis len(results)-1\n",
    "    \n",
    "    def create_graph(result, save_png=True):\n",
    "        \"\"\"Erstellt einen NetworkX-Graph und speichert optional als PNG.\"\"\"\n",
    "        triples = result['triples']\n",
    "        entities = result.get('entities', {})\n",
    "        praedikate = result.get('praedikate', {})\n",
    "        \n",
    "        if not triples:\n",
    "            return None, \"‚ö† Keine Triples zum Visualisieren gefunden.\"\n",
    "        \n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Hilfsfunktion: Entity-ID zu Label aufl√∂sen\n",
    "        def get_label(entity_id):\n",
    "            if entity_id in entities:\n",
    "                return entities[entity_id].get('label', entity_id)\n",
    "            return entity_id\n",
    "        \n",
    "        # Hilfsfunktion: Pr√§dikat-ID zu Label aufl√∂sen\n",
    "        def get_predicate_label(pred_id):\n",
    "            if pred_id in praedikate:\n",
    "                return praedikate[pred_id].get('label', pred_id)\n",
    "            return pred_id\n",
    "        \n",
    "        for triple in triples:\n",
    "            # Unterst√ºtze beide Formate: deutsch (subjekt/objekt) und englisch (subject/object)\n",
    "            subj_id = triple.get('subjekt', triple.get('subject', ''))\n",
    "            pred_id = triple.get('praedikat', triple.get('predicate', ''))\n",
    "            obj_id = triple.get('objekt', triple.get('object', ''))\n",
    "            \n",
    "            # IDs zu Labels aufl√∂sen\n",
    "            subj = get_label(subj_id)\n",
    "            pred = get_predicate_label(pred_id)\n",
    "            obj = get_label(obj_id)\n",
    "            \n",
    "            if subj and obj:\n",
    "                G.add_edge(subj, obj, label=pred)\n",
    "        \n",
    "        if len(G.nodes()) == 0:\n",
    "            return None, \"‚ö† Keine Knoten im Graph gefunden.\"\n",
    "        \n",
    "        pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "        \n",
    "        if save_png:\n",
    "            try:\n",
    "                png_filename = os.path.splitext(result['filename'])[0] + '.png'\n",
    "                png_path = graphs_dir / png_filename\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                nx.draw_networkx(\n",
    "                    G,\n",
    "                    pos=pos,\n",
    "                    node_size=800,\n",
    "                    node_color=\"#b3d9ff\",\n",
    "                    edge_color=\"#888\",\n",
    "                    font_size=8,\n",
    "                    arrows=True,\n",
    "                    with_labels=True\n",
    "                )\n",
    "                edge_labels = nx.get_edge_attributes(G, \"label\")\n",
    "                if edge_labels:\n",
    "                    nx.draw_networkx_edge_labels(G, pos=pos, edge_labels=edge_labels, font_size=7)\n",
    "                plt.axis(\"off\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(png_path, dpi=150)\n",
    "                plt.close()\n",
    "                result['graph_path'] = str(png_path)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö† PNG-Export fehlgeschlagen: {e}\")\n",
    "        \n",
    "        stats = f\"Graph mit {len(G.nodes())} Entit√§ten und {len(G.edges())} Beziehungen\"\n",
    "        return G, stats\n",
    "    \n",
    "    def show_graph(index):\n",
    "        \"\"\"Zeigt Graph an gegebenem Index.\"\"\"\n",
    "        if not (0 <= index < len(results)):\n",
    "            print(f\"‚ùå Ung√ºltiger Index: {index}. Erlaubt: 0 bis {len(results) - 1}\")\n",
    "            return\n",
    "        \n",
    "        result = results[index]\n",
    "        G, stats = create_graph(result)\n",
    "        \n",
    "        if G:\n",
    "            if 'graph_path' in result and os.path.exists(result['graph_path']):\n",
    "                display(Image(filename=result['graph_path']))\n",
    "            else:\n",
    "                # Fallback: inline zeichnen\n",
    "                pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                nx.draw_networkx(\n",
    "                    G,\n",
    "                    pos=pos,\n",
    "                    node_size=800,\n",
    "                    node_color=\"#b3d9ff\",\n",
    "                    edge_color=\"#888\",\n",
    "                    font_size=8,\n",
    "                    arrows=True,\n",
    "                    with_labels=True\n",
    "                )\n",
    "                edge_labels = nx.get_edge_attributes(G, \"label\")\n",
    "                if edge_labels:\n",
    "                    nx.draw_networkx_edge_labels(G, pos=pos, edge_labels=edge_labels, font_size=7)\n",
    "                plt.axis(\"off\")\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            print(f\"\\n{stats}\")\n",
    "        else:\n",
    "            print(stats)\n",
    "    \n",
    "    # Graph anzeigen\n",
    "    show_graph(graph_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fff0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnisse als ZIP herunterladen\n",
    "#\n",
    "## Voraussetzung: Verarbeitung abgeschlossen.\n",
    "\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from IPython.display import FileLink\n",
    "\n",
    "if 'results' not in globals() or not results:\n",
    "    print(\"‚ùå Keine Ergebnisse vorhanden. Bitte f√ºhre zuerst die Verarbeitung aus.\")\n",
    "else:\n",
    "    base_dir = Path(globals().get(\"BASE_DIR\", Path(\"./triple-jupyterhub\").resolve()))\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    zip_filename = f'triple_extraction_results_{timestamp}.zip'\n",
    "    zip_path = base_dir / zip_filename\n",
    "    \n",
    "    graphs_dir = base_dir / \"graphs\"\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        # JSON-Dateien hinzuf√ºgen\n",
    "        for result in results:\n",
    "            output_path = Path(result['output_path'])\n",
    "            arcname = f\"json/{output_path.name}\"\n",
    "            if output_path.exists():\n",
    "                zipf.write(output_path, arcname)\n",
    "        \n",
    "        # Plaintext-Dateien hinzuf√ºgen\n",
    "        for result in results:\n",
    "            plaintext_path = Path(result.get('plaintext_path', ''))\n",
    "            if plaintext_path.exists():\n",
    "                arcname = f\"plaintext/{plaintext_path.name}\"\n",
    "                zipf.write(plaintext_path, arcname)\n",
    "        \n",
    "        # PNG-Grafiken hinzuf√ºgen (falls vorhanden)\n",
    "        if graphs_dir.exists():\n",
    "            for result in results:\n",
    "                graph_path = Path(result.get('graph_path', ''))\n",
    "                if graph_path.exists():\n",
    "                    arcname = f\"graphs/{graph_path.name}\"\n",
    "                    zipf.write(graph_path, arcname)\n",
    "    \n",
    "    print(f\"ZIP erstellt: {zip_filename}\")\n",
    "    print(f\"  ‚Ä¢ {len(results)} JSON-Dateien\")\n",
    "    \n",
    "    plaintext_count = sum(1 for r in results if Path(r.get('plaintext_path', '')).exists())\n",
    "    if plaintext_count > 0:\n",
    "        print(f\"  ‚Ä¢ {plaintext_count} Plaintext-Dateien\")\n",
    "    \n",
    "    graph_count = sum(1 for r in results if Path(r.get('graph_path', '')).exists())\n",
    "    if graph_count > 0:\n",
    "        print(f\"  ‚Ä¢ {graph_count} PNG-Grafiken\")\n",
    "    \n",
    "    display(FileLink(zip_path))\n",
    "    print(f\"\\n‚úì Download-Link angezeigt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c278fd",
   "metadata": {},
   "source": [
    "## Hilfe & Troubleshooting\n",
    "\n",
    "| Problem | L√∂sung |\n",
    "|---------|--------|\n",
    "| **NameError: api_key not defined** | F√ºhre die Zelle \"API-Konfiguration\" aus |\n",
    "| **Ung√ºltiger API-Schl√ºssel** | Pr√ºfe ob der Schl√ºssel korrekt kopiert wurde |\n",
    "| **Rate Limit Error** | Warte kurz und versuche es erneut |\n",
    "| **Timeout** | Versuche es mit weniger oder kleineren Dateien |\n",
    "| **Keine Triples extrahiert** | Erh√∂he den Detailgrad oder passe den Prompt an |\n",
    "| **JSON Parse Error** | Aktiviere \"Debug-Modus\" in der Konfiguration |\n",
    "\n",
    "**API-Schl√ºssel erhalten:**\n",
    "- Gemini: https://aistudio.google.com/apikey\n",
    "- ChatAI: https://chat-ai.academiccloud.de/\n",
    "- OpenAI: https://platform.openai.com/api-keys"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
