{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cdc8fa2",
   "metadata": {},
   "source": [
    "# Triple-Extraktor f√ºr fr√ºhneuzeitliche Briefe\n",
    "\n",
    "**Version:** 0.0.0.1\n",
    "\n",
    "Dieses Notebook extrahiert semantische Triples aus fr√ºhneuzeitlichen Briefen (1750-1809) mit Fokus auf Konzept-Hierarchien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Setup** (einmal ausf√ºhren) { display-mode: \"form\" }\n",
    "#@markdown Installiert ben√∂tigte Pakete und l√§dt den Code.\n",
    "\n",
    "# Version\n",
    "NOTEBOOK_VERSION = \"0.0.0.1\"\n",
    "print(f\"üìì Triple-Extraktor Notebook v{NOTEBOOK_VERSION}\")\n",
    "print(f\"   Letzte Aktualisierung: 05.02.2026\\n\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Pakete installieren\n",
    "!pip install -q pyyaml requests plotly networkx kaleido==0.2.1\n",
    "\n",
    "# Arbeitsverzeichnis erstellen\n",
    "!mkdir -p /content/triple-colab/src\n",
    "!mkdir -p /content/triple-colab/output_json\n",
    "!mkdir -p /content/triple-colab/logs\n",
    "\n",
    "# Python-Path erweitern\n",
    "if '/content/triple-colab/src' not in sys.path:\n",
    "    sys.path.insert(0, '/content/triple-colab/src')\n",
    "\n",
    "# file_client.py erstellen\n",
    "file_client_code = '''\"\"\"Datei-Client f√ºr XML/TXT-Dateien mit TEI-Optimierung.\"\"\"\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import Optional\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class FileClient:\n",
    "    \"\"\"Client zum Lesen von XML/TXT-Dateien mit TEI-Optimierung.\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = file_path\n",
    "        self.file_extension = os.path.splitext(file_path)[1].lower()\n",
    "    \n",
    "    def read_content(self) -> Optional[str]:\n",
    "        \"\"\"Liest den Dateiinhalt und extrahiert relevanten Text.\"\"\"\n",
    "        try:\n",
    "            if self.file_extension == \".xml\":\n",
    "                return self._read_xml()\n",
    "            elif self.file_extension == \".txt\":\n",
    "                return self._read_txt()\n",
    "            else:\n",
    "                logger.warning(f\"Nicht unterst√ºtztes Dateiformat: {self.file_extension}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Lesen von {self.file_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _read_xml(self) -> Optional[str]:\n",
    "        \"\"\"Liest XML-Datei und extrahiert TEI-Body-Text.\"\"\"\n",
    "        try:\n",
    "            tree = ET.parse(self.file_path)\n",
    "            root = tree.getroot()\n",
    "            namespaces = {\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "            body = root.find(\".//tei:body\", namespaces)\n",
    "            if body is not None:\n",
    "                return self._extract_text_from_element(body)\n",
    "            body = root.find(\".//body\")\n",
    "            if body is not None:\n",
    "                return self._extract_text_from_element(body)\n",
    "            return self._extract_text_from_element(root)\n",
    "        except ET.ParseError as e:\n",
    "            logger.error(f\"XML-Parse-Fehler in {self.file_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _read_txt(self) -> Optional[str]:\n",
    "        \"\"\"Liest TXT-Datei.\"\"\"\n",
    "        with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    \n",
    "    def _extract_text_from_element(self, element) -> str:\n",
    "        \"\"\"Extrahiert rekursiv Text aus XML-Element.\"\"\"\n",
    "        texts = []\n",
    "        if element.text:\n",
    "            texts.append(element.text.strip())\n",
    "        for child in element:\n",
    "            texts.append(self._extract_text_from_element(child))\n",
    "            if child.tail:\n",
    "                texts.append(child.tail.strip())\n",
    "        return \" \".join(filter(None, texts))\n",
    "'''\n",
    "\n",
    "with open('/content/triple-colab/src/file_client.py', 'w') as f:\n",
    "    f.write(file_client_code)\n",
    "\n",
    "# openwebui_client.py erstellen\n",
    "openwebui_client_code = '''\"\"\"OpenWebUI-kompatibler Client mit Gemini/OpenAI-Support.\"\"\"\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class OpenWebUIClient:\n",
    "    \"\"\"Client f√ºr OpenAI-kompatible APIs (inkl. Gemini).\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, base_url: str, model: str, temperature: float = 0.1):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.max_retries = 3\n",
    "        self.retry_delay = 2\n",
    "    \n",
    "    def generate_response(self, prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:\n",
    "        \"\"\"Generiert Antwort mit automatischem Retry.\"\"\"\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                if \"generativelanguage.googleapis.com\" in self.base_url:\n",
    "                    return self._call_gemini_api(prompt, system_prompt)\n",
    "                else:\n",
    "                    return self._call_openai_api(prompt, system_prompt)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Versuch {attempt + 1}/{self.max_retries} fehlgeschlagen: {e}\")\n",
    "                if attempt < self.max_retries - 1:\n",
    "                    time.sleep(self.retry_delay * (attempt + 1))\n",
    "                else:\n",
    "                    logger.error(f\"Alle Versuche fehlgeschlagen: {e}\")\n",
    "                    return None\n",
    "    \n",
    "    def _call_gemini_api(self, prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:\n",
    "        \"\"\"Ruft Gemini API auf.\"\"\"\n",
    "        url = f\"{self.base_url}:generateContent?key={self.api_key}\"\n",
    "        payload = {\n",
    "            \"contents\": [{\"parts\": [{\"text\": prompt}]}],\n",
    "            \"generationConfig\": {\"temperature\": self.temperature}\n",
    "        }\n",
    "        if system_prompt:\n",
    "            payload[\"systemInstruction\"] = {\"parts\": [{\"text\": system_prompt}]}\n",
    "        response = requests.post(url, json=payload, timeout=120)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "    \n",
    "    def _call_openai_api(self, prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:\n",
    "        \"\"\"Ruft OpenAI-kompatible API auf.\"\"\"\n",
    "        url = f\"{self.base_url}/chat/completions\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        messages = []\n",
    "        if system_prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": self.temperature\n",
    "        }\n",
    "        response = requests.post(url, headers=headers, json=payload, timeout=120)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "'''\n",
    "\n",
    "with open('/content/triple-colab/src/openwebui_client.py', 'w') as f:\n",
    "    f.write(openwebui_client_code)\n",
    "\n",
    "print(\"‚úì Setup abgeschlossen!\")\n",
    "print(\"‚úì Pakete installiert\")\n",
    "print(\"‚úì Code-Module erstellt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f367c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **API-Konfiguration** { display-mode: \"form\" }\n",
    "\n",
    "#@markdown ### W√§hle deinen API-Provider:\n",
    "api_provider = \"Gemini (Google)\" #@param [\"Gemini (Google)\", \"ChatAI (AcademicCloud)\"]\n",
    "\n",
    "#@markdown ### API-Schl√ºssel:\n",
    "#@markdown **Wichtig:** Gib niemals deinen API-Schl√ºssel in √∂ffentlichen Notebooks weiter! L√∂sche ihn vor dem Teilen.\n",
    "api_key = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### Eigenes Modell (optional):\n",
    "#@markdown Leer lassen f√ºr Standard-Modell des Providers\n",
    "custom_model = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### Detailgrad der Extraktion:\n",
    "#@markdown Wie ausf√ºhrlich sollen die Triples sein? (1=nur Kernaussagen, 10=sehr detailliert)\n",
    "granularity = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
    "\n",
    "#@markdown ### Temperatur (Kreativit√§t):\n",
    "#@markdown Wie kreativ soll die KI antworten? (0=deterministisch, 1=sehr kreativ)\n",
    "temperature = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "\n",
    "#@markdown ### Erweiterte Optionen:\n",
    "#@markdown Datei-Metadaten in Ergebnissen speichern (Dateiname, Datum, etc.):\n",
    "save_file_metadata = True #@param {type:\"boolean\"}\n",
    "#@markdown Debug-Modus: Zeige KI-Antworten bei Fehlern (hilft bei Problemanalyse):\n",
    "show_debug_output = False #@param {type:\"boolean\"}\n",
    "\n",
    "# API-Schl√ºssel validieren\n",
    "if not api_key or len(api_key.strip()) < 10:\n",
    "    raise ValueError(\n",
    "        \"‚ùå Ung√ºltiger API-Schl√ºssel!\\n\\n\"\n",
    "        \"Bitte gib einen g√ºltigen API-Schl√ºssel ein.\\n\\n\"\n",
    "        \"API-Schl√ºssel erhalten:\\n\"\n",
    "        \"‚Ä¢ Gemini: https://aistudio.google.com/apikey\\n\"\n",
    "        \"‚Ä¢ ChatAI: https://chat-ai.academiccloud.de/\"\n",
    "    )\n",
    "\n",
    "# Konfiguration basierend auf Provider\n",
    "if api_provider == \"Gemini (Google)\":\n",
    "    if custom_model:\n",
    "        selected_model = custom_model\n",
    "        base_url = f\"https://generativelanguage.googleapis.com/v1beta/models/{custom_model}\"\n",
    "    else:\n",
    "        selected_model = \"gemini-2.0-flash\"\n",
    "        base_url = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash\"\n",
    "else:  # ChatAI\n",
    "    selected_model = custom_model if custom_model else \"llama-3.3-70b-instruct\"\n",
    "    base_url = \"https://chat-ai.academiccloud.de/v1\"\n",
    "\n",
    "# Konfiguration speichern\n",
    "selected_config = {\n",
    "    'provider': api_provider,\n",
    "    'api_key': api_key,\n",
    "    'base_url': base_url,\n",
    "    'model': selected_model,\n",
    "    'temperature': temperature,\n",
    "    'granularity': granularity,\n",
    "    'include_metadata': save_file_metadata,\n",
    "    'verbose': show_debug_output\n",
    "}\n",
    "\n",
    "print(f\"‚úì Konfiguration gespeichert\")\n",
    "print(f\"  Provider: {api_provider}\")\n",
    "print(f\"  Modell: {selected_model}\")\n",
    "print(f\"  Detailgrad: {granularity}\")\n",
    "print(f\"  Temperatur: {temperature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d7a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **System-Prompt bearbeiten** (optional) { display-mode: \"form\" }\n",
    "#@markdown Hier kannst du den System-Prompt anpassen.\n",
    "\n",
    "#@markdown ### Eigenen System-Prompt verwenden:\n",
    "use_custom_prompt = False #@param {type:\"boolean\"}\n",
    "\n",
    "# Default-Prompt\n",
    "DEFAULT_PROMPT = \"\"\"# Prompt: Extraktion semantischer Triples aus fr√ºhneuzeitlichen Briefen  \n",
    "**(LLM-optimiert, strikt themenzentriert, konzept-hierarchisch, nicht redundant)**\n",
    "\n",
    "Du bist ein Experte f√ºr fr√ºhneuzeitliche Korrespondenz im **mitteleurop√§ischen Raum des sp√§ten 18. und fr√ºhen 19. Jahrhunderts (ca. 1750‚Äì1809)**.  \n",
    "Deine Aufgabe ist die Extraktion **kanonischer, nicht redundanter** semantischer Triples  \n",
    "(**Subjekt ‚Äì Pr√§dikat ‚Äì Objekt**) aus historischen Briefen dieses Zeitraums.\n",
    "\n",
    "Der **historische Hintergrund Mitteleuropas** (Bildungswesen, Konfessionen, soziale Ordnung, Elternautorit√§t, Universit√§tskultur, Ehr- und Reputationsnormen, Briefkultur) ist **stillschweigend zu ber√ºcksichtigen**, ohne anachronistische Begriffe oder moderne Konzepte einzuf√ºhren.\n",
    "\n",
    "Ziel ist ein **semantisch dichtes, stabiles, themenvergleichbares Ergebnis**, das sich f√ºr LLMs, Wissensgraphen und vergleichende Analysen eignet.\n",
    "\n",
    "---\n",
    "\n",
    "## INPUT\n",
    "Du erh√§ltst:\n",
    "- `abstraktionslevel` (1‚Äì5)\n",
    "- `brieftext` (vollst√§ndiger Text inkl. Briefkopf)\n",
    "- TEI-XML, ignoriere den TEI-header\n",
    "- ignoriere die Kommentare\n",
    "- ignoriere die Editorial Notes\n",
    "\n",
    "---\n",
    "\n",
    "## OUTPUT (VERBINDLICH)\n",
    "Gib **ausschlie√ülich reines JSON** aus:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"entities\": {...},\n",
    "  \"praedikate\": {...},\n",
    "  \"triples\": [...],\n",
    "  \"parameter\": {...}\n",
    "}\n",
    "```\n",
    "\n",
    "Keine Erkl√§rungen, kein Markdown, keine Zusatzfelder.\n",
    "\n",
    "---\n",
    "\n",
    "## VERBINDLICHE NAMENSNORMALISIERUNG\n",
    "\n",
    "Die folgenden historischen oder vollst√§ndigen Namensformen sind **immer** auf die kanonische Form zu normalisieren:\n",
    "\n",
    "- Johann Paul Friedrich Richter ‚Üí Jean Paul  \n",
    "- Johann Wolfgang von G√∂the ‚Üí Goethe  \n",
    "- Gotthold Ephraim Lessing ‚Üí Lessing  \n",
    "- Immanuel Kant ‚Üí Kant  \n",
    "- Friedrich Schiller ‚Üí Schiller  \n",
    "\n",
    "Weitere Varianten sind **analog zu vereinheitlichen**  \n",
    "(b√ºrgerlicher Vollname ‚Üí etablierter Werkname).\n",
    "\n",
    "---\n",
    "\n",
    "## ABSTRAKTIONSLEVEL ‚Üí ZIELANZAHL TRIPLES\n",
    "\n",
    "| Level | Ziel |\n",
    "|------|------|\n",
    "| 1 | 1‚Äì2 Triples ‚Äì Kernaussage |\n",
    "| 2 | 3‚Äì5 Triples ‚Äì Kernaussage + Hauptthemen |\n",
    "| 3 | 8‚Äì12 Triples ‚Äì Themen + Argumentstruktur |\n",
    "| 4 | 12‚Äì20 Triples ‚Äì thematisch relevante Details |\n",
    "| 5 | 25+ Triples ‚Äì implizite, klar ableitbare Bedeutungen |\n",
    "\n",
    "---\n",
    "\n",
    "## KERNPRINZIP: KONZEPT-HIERARCHIE STATT AKTEURS-GRAPH\n",
    "\n",
    "Der Brief ist **prim√§r als thematisches System** zu modellieren, nicht als Abfolge von Handlungen oder Personen.\n",
    "\n",
    "### VERBINDLICHER MODELLIERUNGSPFAD\n",
    "\n",
    "#### 1. OBERKONZEPTE IDENTIFIZIEREN  \n",
    "Identifiziere zuerst **√ºbergeordnete Themenfelder** (Oberkonzepte), z.B.:\n",
    "\n",
    "- Emotion  \n",
    "- Krankheit  \n",
    "- Liebe  \n",
    "- Freundschaft  \n",
    "- Soziale Ordnung  \n",
    "- Moral / Gewissen  \n",
    "- Bildung  \n",
    "- Lebensweg  \n",
    "- Zukunft / Erwartung  \n",
    "\n",
    "Diese werden als **Konzept-Entit√§ten (Typ: Konzept)** modelliert.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. SUBKONZEPTE ABLEITEN  \n",
    "Leite daraus **inhaltlich unterscheidbare Unterthemen** ab.\n",
    "\n",
    "Beispiele:\n",
    "- Emotion ‚Üí Schwermut, Angst, Hoffnung  \n",
    "- Krankheit ‚Üí Hypochondrie, k√∂rperliche Schw√§che  \n",
    "- Soziale Ordnung ‚Üí elterliche Autorit√§t, soziale Kontrolle, Ruf  \n",
    "\n",
    "Subkonzepte sind **immer Konzepte, niemals Personenattribute**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. KONZEPT‚ÄìKONZEPT-BEZIEHUNGEN MODELLIEREN  \n",
    "Modelliere bevorzugt Beziehungen **zwischen Ober- und Subkonzepten** oder zwischen Subkonzepten.\n",
    "\n",
    "Beispiele:\n",
    "- Schwermut ist_Subkonzept_von Emotion  \n",
    "- Hypochondrie ist_Subkonzept_von Krankheit  \n",
    "- Soziale_Kontrolle versch√§rft Emotionale_Krise  \n",
    "- Krankheit beeinflusst Lebenswille  \n",
    "\n",
    "**Mindestens 50 % aller Triples m√ºssen Konzept‚ÜîKonzept sein.**\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. PERSONEN NUR ALS TR√ÑGER (NACHRANGIG)\n",
    "Personen d√ºrfen **nur** erscheinen, wenn sie:\n",
    "- Tr√§ger eines Konzepts sind\n",
    "- von einem Konzept betroffen sind\n",
    "- eine thematische Dynamik ausl√∂sen\n",
    "\n",
    "Zul√§ssige Muster:\n",
    "- Krankheit betrifft Wagner  \n",
    "- Emotionale_Krise betrifft Empf√§nger  \n",
    "\n",
    "Unzul√§ssig:\n",
    "- Person ‚Üî Person ohne thematische Vermittlung\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. ORTE NUR ALS THEMATISCHER RAHMEN (AUSNAHME)\n",
    "Orte d√ºrfen nur modelliert werden, wenn sie:\n",
    "- einen thematischen Zustand rahmen oder beeinflussen\n",
    "- sozial oder symbolisch relevant sind\n",
    "\n",
    "Unzul√§ssig:\n",
    "- reine Lokalisierungen (‚Äûschreibt aus X\")\n",
    "\n",
    "---\n",
    "\n",
    "## AUFL√ñSUNG VON ZUSTANDS-, ROLLEN- UND KOMPOSIT-ENTIT√ÑTEN\n",
    "\n",
    "Komplexe Zuschreibungen wie  \n",
    "‚ÄûX-Zustand von Person Y\"  \n",
    "d√ºrfen **nicht** als eigene Entit√§t stehen bleiben.\n",
    "\n",
    "Sie sind **immer** zu zerlegen in:\n",
    "1. ein **abstraktes Konzept**\n",
    "2. eine **explizite Beziehung**\n",
    "\n",
    "Beispiel:\n",
    "- ‚ÄûKrankheitszustand Wagners\"  \n",
    "  ‚Üí Konzept: Krankheit  \n",
    "  ‚Üí Triple: Krankheit betrifft Wagner\n",
    "\n",
    "---\n",
    "\n",
    "## REDUNDANZ-REGELN (STRIKT)\n",
    "\n",
    "1. Keine Dubletten  \n",
    "2. Keine Spiegelungen ohne Mehrwert  \n",
    "3. Keine leeren Kommunikations-Triples  \n",
    "4. Komplexe Sachverhalte als Ereignisknoten  \n",
    "5. Verdichten statt auflisten  \n",
    "\n",
    "---\n",
    "\n",
    "## ENTIT√ÑTEN\n",
    "\n",
    "**Typen**:  \n",
    "Person | Ort | Werk | Institution | Ereignis | Konzept | Zeitpunkt | Sonstiges  \n",
    "\n",
    "**Normalisierung**:\n",
    "- ‚Äûich\" ‚Üí Absender\n",
    "- ‚ÄûSie\" ‚Üí Empf√§nger\n",
    "- moderne Rechtschreibung\n",
    "- vollst√§ndige Datumsangaben\n",
    "- historische Ortsnamen beibehalten\n",
    "\n",
    "**IDs**: E1, E2, E3, ‚Ä¶\n",
    "\n",
    "---\n",
    "\n",
    "## PR√ÑDIKATE\n",
    "\n",
    "Verwende ein **kleines, stabiles Pr√§dikatsinventar**  \n",
    "(Level 3: ca. 10‚Äì16 Pr√§dikate).\n",
    "\n",
    "Beispiele:\n",
    "- ist_Subkonzept_von\n",
    "- beeinflusst\n",
    "- versch√§rft\n",
    "- beruhigt\n",
    "- reguliert\n",
    "- verursacht\n",
    "- interpretiert_als\n",
    "- betrifft\n",
    "- unterliegt\n",
    "- rahmt\n",
    "- empfiehlt\n",
    "\n",
    "---\n",
    "\n",
    "## JSON-FORMAT (VERBINDLICH)\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"entities\": {\n",
    "    \"E1\": {\"label\": \"...\", \"typ\": \"...\"}\n",
    "  },\n",
    "  \"praedikate\": {\n",
    "    \"P1\": {\"label\": \"...\", \"normalisiert_von\": [\"...\"]}\n",
    "  },\n",
    "  \"triples\": [\n",
    "    {\"subjekt\": \"E1\", \"praedikat\": \"P1\", \"objekt\": \"E2\"}\n",
    "  ],\n",
    "  \"parameter\": {\n",
    "    \"granularitaet\": 3,\n",
    "    \"anzahl_triples\": 10\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## START\n",
    "Analysiere nun den bereitgestellten `brieftext` gem√§√ü diesen Regeln  \n",
    "und gib **ausschlie√ülich das JSON** aus.\"\"\"\n",
    "\n",
    "if use_custom_prompt:\n",
    "    print(\"üìù Bearbeite deinen System-Prompt:\\n\")\n",
    "    \n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    \n",
    "    # Textarea Widget\n",
    "    prompt_textarea = widgets.Textarea(\n",
    "        value=DEFAULT_PROMPT,\n",
    "        placeholder='System-Prompt hier eingeben...',\n",
    "        description='',\n",
    "        layout=widgets.Layout(width='100%', height='300px')\n",
    "    )\n",
    "    \n",
    "    # Speichern-Button\n",
    "    save_button = widgets.Button(\n",
    "        description='‚úì Prompt speichern',\n",
    "        button_style='success',\n",
    "        layout=widgets.Layout(width='200px')\n",
    "    )\n",
    "    \n",
    "    output_area = widgets.Output()\n",
    "    \n",
    "    def on_save_click(b):\n",
    "        with output_area:\n",
    "            output_area.clear_output()\n",
    "            global CUSTOM_PROMPT\n",
    "            CUSTOM_PROMPT = prompt_textarea.value\n",
    "            print(f\"‚úì System-Prompt gespeichert ({len(CUSTOM_PROMPT)} Zeichen)\")\n",
    "    \n",
    "    save_button.on_click(on_save_click)\n",
    "    \n",
    "    # Anzeigen\n",
    "    display(prompt_textarea)\n",
    "    display(save_button)\n",
    "    display(output_area)\n",
    "    \n",
    "    # Initial speichern\n",
    "    CUSTOM_PROMPT = DEFAULT_PROMPT\n",
    "    \n",
    "else:\n",
    "    CUSTOM_PROMPT = None\n",
    "    print(\"‚Ñπ Standard-Prompt wird verwendet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88338e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Dateien hochladen** { display-mode: \"form\" }\n",
    "#@markdown Lade deine XML-Dateien oder ein ZIP-Archiv hoch.\n",
    "\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import shutil\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Upload-Verzeichnis\n",
    "upload_dir = '/content/triple-colab/uploads'\n",
    "\n",
    "# Globale Variable f√ºr Dateiliste\n",
    "if 'uploaded_files' not in globals():\n",
    "    uploaded_files = []\n",
    "\n",
    "def reset_all():\n",
    "    \"\"\"Setzt alles zur√ºck au√üer API-Konfiguration.\"\"\"\n",
    "    global uploaded_files, results, current_graph_index\n",
    "    \n",
    "    # L√∂sche Upload-Verzeichnis\n",
    "    if os.path.exists(upload_dir):\n",
    "        shutil.rmtree(upload_dir)\n",
    "    os.makedirs(upload_dir, exist_ok=True)\n",
    "    \n",
    "    # L√∂sche Ergebnisse\n",
    "    output_dir = '/content/triple-colab/output_json'\n",
    "    if os.path.exists(output_dir):\n",
    "        for file in os.listdir(output_dir):\n",
    "            os.remove(os.path.join(output_dir, file))\n",
    "    \n",
    "    graphs_dir = '/content/triple-colab/graphs'\n",
    "    if os.path.exists(graphs_dir):\n",
    "        shutil.rmtree(graphs_dir)\n",
    "    \n",
    "    # Variablen zur√ºcksetzen\n",
    "    uploaded_files = []\n",
    "    results = []\n",
    "    current_graph_index = 0\n",
    "    \n",
    "    print(\"‚úì Neustart durchgef√ºhrt - API-Konfiguration bleibt erhalten\")\n",
    "\n",
    "def upload_files():\n",
    "    \"\"\"Datei-Upload Handler.\"\"\"\n",
    "    global uploaded_files\n",
    "    \n",
    "    if uploaded_files:\n",
    "        print(\"‚ö† Es sind bereits Dateien hochgeladen. Nutze 'Neustart', um neue Dateien hochzuladen.\")\n",
    "        return\n",
    "    \n",
    "    # Upload-Verzeichnis sicherstellen\n",
    "    os.makedirs(upload_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"Bitte w√§hle deine Dateien aus...\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Hochgeladene Dateien verarbeiten\n",
    "    for filename, content in uploaded.items():\n",
    "        filepath = os.path.join(upload_dir, filename)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(content)\n",
    "        \n",
    "        # ZIP-Archive entpacken\n",
    "        if filename.endswith('.zip'):\n",
    "            print(f\"üì¶ Entpacke {filename}...\")\n",
    "            with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "                zip_ref.extractall(upload_dir)\n",
    "            os.remove(filepath)\n",
    "            print(f\"‚úì {filename} erfolgreich entpackt\")\n",
    "    \n",
    "    # XML-Dateien sammeln\n",
    "    for root, dirs, files_in_dir in os.walk(upload_dir):\n",
    "        for file in files_in_dir:\n",
    "            if file.endswith('.xml'):\n",
    "                uploaded_files.append(os.path.join(root, file))\n",
    "    \n",
    "    update_file_list()\n",
    "\n",
    "def delete_file(filepath):\n",
    "    \"\"\"L√∂scht eine einzelne Datei.\"\"\"\n",
    "    global uploaded_files\n",
    "    \n",
    "    if filepath in uploaded_files:\n",
    "        uploaded_files.remove(filepath)\n",
    "        if os.path.exists(filepath):\n",
    "            os.remove(filepath)\n",
    "    \n",
    "    update_file_list()\n",
    "\n",
    "def update_file_list():\n",
    "    \"\"\"Aktualisiert die Dateilisten-Anzeige.\"\"\"\n",
    "    with file_list_output:\n",
    "        clear_output()\n",
    "        \n",
    "        if not uploaded_files:\n",
    "            print(\"Keine Dateien hochgeladen.\")\n",
    "        else:\n",
    "            print(f\"‚úì {len(uploaded_files)} XML-Datei(en):\\n\")\n",
    "            \n",
    "            for filepath in uploaded_files:\n",
    "                filename = os.path.basename(filepath)\n",
    "                \n",
    "                # L√∂sch-Button f√ºr jede Datei\n",
    "                delete_btn = widgets.Button(\n",
    "                    description='üóë',\n",
    "                    button_style='danger',\n",
    "                    layout=widgets.Layout(width='50px', height='28px')\n",
    "                )\n",
    "                \n",
    "                label = widgets.Label(value=filename)\n",
    "                \n",
    "                def make_delete_handler(fp):\n",
    "                    def handler(b):\n",
    "                        delete_file(fp)\n",
    "                    return handler\n",
    "                \n",
    "                delete_btn.on_click(make_delete_handler(filepath))\n",
    "                \n",
    "                row = widgets.HBox([delete_btn, label])\n",
    "                display(row)\n",
    "\n",
    "# UI-Komponenten\n",
    "upload_button = widgets.Button(\n",
    "    description='üìÅ Dateien hochladen',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "reset_button = widgets.Button(\n",
    "    description='üîÑ Neustart',\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "\n",
    "file_list_output = widgets.Output()\n",
    "\n",
    "# Event Handler\n",
    "upload_button.on_click(lambda b: upload_files())\n",
    "reset_button.on_click(lambda b: (reset_all(), update_file_list()))\n",
    "\n",
    "# UI anzeigen\n",
    "display(widgets.HBox([upload_button, reset_button]))\n",
    "display(file_list_output)\n",
    "\n",
    "# Initial anzeigen\n",
    "update_file_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f1c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Verarbeitung starten** { display-mode: \"form\" }\n",
    "#@markdown Startet die Triple-Extraktion f√ºr alle hochgeladenen Dateien.\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "from file_client import FileClient\n",
    "from openwebui_client import OpenWebUIClient\n",
    "\n",
    "# Validierung\n",
    "if 'selected_config' not in globals():\n",
    "    raise ValueError(\n",
    "        \"‚ùå Keine API-Konfiguration gefunden!\\n\\n\"\n",
    "        \"Bitte f√ºhre zuerst die Zelle 'API-Konfiguration' aus.\"\n",
    "    )\n",
    "\n",
    "if 'api_key' not in globals() or not api_key:\n",
    "    raise ValueError(\n",
    "        \"‚ùå Kein API-Schl√ºssel gefunden!\\n\\n\"\n",
    "        \"Bitte f√ºhre die Zelle 'API-Konfiguration' aus und gib deinen API-Schl√ºssel ein.\"\n",
    "    )\n",
    "\n",
    "if 'uploaded_files' not in globals() or not uploaded_files:\n",
    "    raise ValueError(\n",
    "        \"‚ùå Keine Dateien hochgeladen!\\n\\n\"\n",
    "        \"Bitte f√ºhre zuerst die Zelle 'Dateien hochladen' aus.\"\n",
    "    )\n",
    "\n",
    "# Client initialisieren\n",
    "client = OpenWebUIClient(\n",
    "    api_key=selected_config['api_key'],\n",
    "    base_url=selected_config['base_url'],\n",
    "    model=selected_config['model'],\n",
    "    temperature=selected_config['temperature']\n",
    ")\n",
    "\n",
    "# System-Prompt\n",
    "system_prompt = CUSTOM_PROMPT if ('use_custom_prompt' in globals() and use_custom_prompt) else None\n",
    "\n",
    "# Prompt-Template\n",
    "def create_prompt(text, granularity):\n",
    "    return f\"\"\"Extrahiere semantische Triples aus folgendem historischen Brieftext.\n",
    "\n",
    "Granularit√§t: {granularity}/10 (1=grob, 10=sehr detailliert)\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Antworte NUR mit g√ºltigem JSON im Format:\n",
    "{{\n",
    "  \"triples\": [\n",
    "    {{\"subject\": \"...\", \"predicate\": \"...\", \"object\": \"...\"}}\n",
    "  ]\n",
    "}}\"\"\"\n",
    "\n",
    "# Verarbeitung\n",
    "results = []\n",
    "output_dir = '/content/triple-colab/output_json'\n",
    "\n",
    "print(f\"Verarbeite {len(uploaded_files)} Datei(en)...\\n\")\n",
    "\n",
    "for i, filepath in enumerate(uploaded_files, 1):\n",
    "    filename = os.path.basename(filepath)\n",
    "    print(f\"[{i}/{len(uploaded_files)}] {filename}\")\n",
    "    \n",
    "    try:\n",
    "        # Text einlesen\n",
    "        file_client = FileClient(filepath)\n",
    "        text = file_client.read_content()\n",
    "        \n",
    "        if not text:\n",
    "            print(f\"  ‚ö† Konnte Text nicht extrahieren\")\n",
    "            continue\n",
    "        \n",
    "        # API-Anfrage\n",
    "        prompt = create_prompt(text, selected_config['granularity'])\n",
    "        response = client.generate_response(prompt, system_prompt)\n",
    "        \n",
    "        if not response:\n",
    "            print(f\"  ‚ùå Keine Antwort erhalten\")\n",
    "            continue\n",
    "        \n",
    "        # JSON parsen\n",
    "        try:\n",
    "            clean_response = response.strip()\n",
    "            if clean_response.startswith('```'):\n",
    "                clean_response = '\\n'.join(clean_response.split('\\n')[1:-1])\n",
    "            if clean_response.startswith('json'):\n",
    "                clean_response = '\\n'.join(clean_response.split('\\n')[1:])\n",
    "            \n",
    "            data = json.loads(clean_response)\n",
    "            triple_count = len(data.get('triples', []))\n",
    "            \n",
    "            # Ergebnis speichern\n",
    "            output_filename = os.path.splitext(filename)[0] + '.json'\n",
    "            output_path = os.path.join(output_dir, output_filename)\n",
    "            \n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            results.append({\n",
    "                'filename': filename,\n",
    "                'triples': data.get('triples', []),\n",
    "                'entities': data.get('entities', {}),\n",
    "                'praedikate': data.get('praedikate', {}),\n",
    "                'output_path': output_path\n",
    "            })\n",
    "            \n",
    "            print(f\"  ‚úì {triple_count} Triples extrahiert\")\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"  ‚ùå JSON-Parse-Fehler: {e}\")\n",
    "            if selected_config.get('verbose', False):\n",
    "                print(f\"  Response: {response[:200]}...\")\n",
    "            continue\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Fehler: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n‚úì Verarbeitung abgeschlossen!\")\n",
    "print(f\"  {len(results)} von {len(uploaded_files)} Dateien erfolgreich verarbeitet\")\n",
    "total_triples = sum(len(r['triples']) for r in results)\n",
    "print(f\"  {total_triples} Triples gesamt extrahiert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf617d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Ergebnis visualisieren** { display-mode: \"form\" }\n",
    "#@markdown Zeigt die Wissensgraphen als durchbl√§tterbare Galerie.\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "\n",
    "if 'results' not in globals() or not results:\n",
    "    print(\"‚ùå Keine Ergebnisse vorhanden. Bitte f√ºhre zuerst die Verarbeitung aus.\")\n",
    "else:\n",
    "    # Graphs-Verzeichnis erstellen\n",
    "    graphs_dir = '/content/triple-colab/graphs'\n",
    "    os.makedirs(graphs_dir, exist_ok=True)\n",
    "    \n",
    "    # Aktueller Index (global f√ºr Navigation)\n",
    "    if 'current_graph_index' not in globals():\n",
    "        current_graph_index = 0\n",
    "    \n",
    "    def create_graph(result, save_png=True):\n",
    "        \"\"\"Erstellt einen Plotly-Graph aus Triples.\"\"\"\n",
    "        triples = result['triples']\n",
    "        entities = result.get('entities', {})\n",
    "        praedikate = result.get('praedikate', {})\n",
    "        \n",
    "        if not triples:\n",
    "            return None, \"‚ö† Keine Triples zum Visualisieren gefunden.\"\n",
    "        \n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Hilfsfunktion: Entity-ID zu Label aufl√∂sen\n",
    "        def get_label(entity_id):\n",
    "            if entity_id in entities:\n",
    "                return entities[entity_id].get('label', entity_id)\n",
    "            return entity_id\n",
    "        \n",
    "        # Hilfsfunktion: Pr√§dikat-ID zu Label aufl√∂sen\n",
    "        def get_predicate_label(pred_id):\n",
    "            if pred_id in praedikate:\n",
    "                return praedikate[pred_id].get('label', pred_id)\n",
    "            return pred_id\n",
    "        \n",
    "        for triple in triples:\n",
    "            # Unterst√ºtze beide Formate: deutsch (subjekt/objekt) und englisch (subject/object)\n",
    "            subj_id = triple.get('subjekt', triple.get('subject', ''))\n",
    "            pred_id = triple.get('praedikat', triple.get('predicate', ''))\n",
    "            obj_id = triple.get('objekt', triple.get('object', ''))\n",
    "            \n",
    "            # IDs zu Labels aufl√∂sen\n",
    "            subj = get_label(subj_id)\n",
    "            pred = get_predicate_label(pred_id)\n",
    "            obj = get_label(obj_id)\n",
    "            \n",
    "            if subj and obj:\n",
    "                G.add_edge(subj, obj, label=pred)\n",
    "        \n",
    "        if len(G.nodes()) == 0:\n",
    "            return None, \"‚ö† Keine Knoten im Graph gefunden.\"\n",
    "        \n",
    "        pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "        \n",
    "        # Edge-Traces\n",
    "        edge_trace = []\n",
    "        for edge in G.edges():\n",
    "            x0, y0 = pos[edge[0]]\n",
    "            x1, y1 = pos[edge[1]]\n",
    "            edge_trace.append(\n",
    "                go.Scatter(\n",
    "                    x=[x0, x1, None],\n",
    "                    y=[y0, y1, None],\n",
    "                    mode='lines',\n",
    "                    line=dict(width=1, color='#888'),\n",
    "                    hoverinfo='none',\n",
    "                    showlegend=False\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Node-Trace\n",
    "        node_x = []\n",
    "        node_y = []\n",
    "        node_text = []\n",
    "        \n",
    "        for node in G.nodes():\n",
    "            x, y = pos[node]\n",
    "            node_x.append(x)\n",
    "            node_y.append(y)\n",
    "            node_text.append(node)\n",
    "        \n",
    "        node_trace = go.Scatter(\n",
    "            x=node_x,\n",
    "            y=node_y,\n",
    "            mode='markers+text',\n",
    "            text=node_text,\n",
    "            textposition='top center',\n",
    "            hoverinfo='text',\n",
    "            marker=dict(\n",
    "                size=20,\n",
    "                color='lightblue',\n",
    "                line=dict(width=2, color='darkblue')\n",
    "            ),\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        # Figure erstellen\n",
    "        fig = go.Figure(\n",
    "            data=edge_trace + [node_trace],\n",
    "            layout=go.Layout(\n",
    "                title=f\"Wissensgraph: {result['filename']}\",\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20, l=20, r=20, t=40),\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                height=600,\n",
    "                width=800\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # PNG speichern\n",
    "        if save_png:\n",
    "            try:\n",
    "                png_filename = os.path.splitext(result['filename'])[0] + '.png'\n",
    "                png_path = os.path.join(graphs_dir, png_filename)\n",
    "                fig.write_image(png_path, width=1200, height=800)\n",
    "                result['graph_path'] = png_path\n",
    "            except Exception as e:\n",
    "                # PNG-Export fehlgeschlagen, aber Graph kann trotzdem angezeigt werden\n",
    "                pass\n",
    "        \n",
    "        stats = f\"Graph mit {len(G.nodes())} Entit√§ten und {len(G.edges())} Beziehungen\"\n",
    "        return fig, stats\n",
    "    \n",
    "    def show_graph(index):\n",
    "        \"\"\"Zeigt Graph an gegebenem Index.\"\"\"\n",
    "        with graph_output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if 0 <= index < len(results):\n",
    "                result = results[index]\n",
    "                fig, stats = create_graph(result)\n",
    "                \n",
    "                if fig:\n",
    "                    fig.show()\n",
    "                    print(f\"\\n{stats}\")\n",
    "                else:\n",
    "                    print(stats)\n",
    "            \n",
    "            # Navigation-Status aktualisieren\n",
    "            nav_label.value = f\"Datei {index + 1} von {len(results)}\"\n",
    "            prev_btn.disabled = (index == 0)\n",
    "            next_btn.disabled = (index == len(results) - 1)\n",
    "    \n",
    "    def on_prev_click(b):\n",
    "        global current_graph_index\n",
    "        if current_graph_index > 0:\n",
    "            current_graph_index -= 1\n",
    "            show_graph(current_graph_index)\n",
    "    \n",
    "    def on_next_click(b):\n",
    "        global current_graph_index\n",
    "        if current_graph_index < len(results) - 1:\n",
    "            current_graph_index += 1\n",
    "            show_graph(current_graph_index)\n",
    "    \n",
    "    # Navigation-Buttons\n",
    "    prev_btn = widgets.Button(\n",
    "        description='‚Üê Zur√ºck',\n",
    "        button_style='info',\n",
    "        layout=widgets.Layout(width='120px')\n",
    "    )\n",
    "    \n",
    "    next_btn = widgets.Button(\n",
    "        description='Weiter ‚Üí',\n",
    "        button_style='info',\n",
    "        layout=widgets.Layout(width='120px')\n",
    "    )\n",
    "    \n",
    "    nav_label = widgets.Label(\n",
    "        value=f\"Datei 1 von {len(results)}\",\n",
    "        layout=widgets.Layout(width='150px')\n",
    "    )\n",
    "    \n",
    "    prev_btn.on_click(on_prev_click)\n",
    "    next_btn.on_click(on_next_click)\n",
    "    \n",
    "    graph_output = widgets.Output()\n",
    "    \n",
    "    # UI anzeigen\n",
    "    nav_box = widgets.HBox([prev_btn, nav_label, next_btn], layout=widgets.Layout(justify_content='center'))\n",
    "    display(nav_box)\n",
    "    display(graph_output)\n",
    "    \n",
    "    # Ersten Graph anzeigen\n",
    "    show_graph(current_graph_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fff0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Ergebnisse als ZIP herunterladen** { display-mode: \"form\" }\n",
    "#@markdown L√§dt alle JSON-Ergebnisse und PNG-Grafiken als ZIP-Archiv herunter.\n",
    "\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "if 'results' not in globals() or not results:\n",
    "    print(\"‚ùå Keine Ergebnisse vorhanden. Bitte f√ºhre zuerst die Verarbeitung aus.\")\n",
    "else:\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    zip_filename = f'triple_extraction_results_{timestamp}.zip'\n",
    "    zip_path = f'/content/{zip_filename}'\n",
    "    \n",
    "    graphs_dir = '/content/triple-colab/graphs'\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        # JSON-Dateien hinzuf√ºgen\n",
    "        for result in results:\n",
    "            output_path = result['output_path']\n",
    "            arcname = f\"json/{os.path.basename(output_path)}\"\n",
    "            zipf.write(output_path, arcname)\n",
    "        \n",
    "        # PNG-Grafiken hinzuf√ºgen (falls vorhanden)\n",
    "        if os.path.exists(graphs_dir):\n",
    "            for result in results:\n",
    "                if 'graph_path' in result and os.path.exists(result['graph_path']):\n",
    "                    graph_path = result['graph_path']\n",
    "                    arcname = f\"graphs/{os.path.basename(graph_path)}\"\n",
    "                    zipf.write(graph_path, arcname)\n",
    "    \n",
    "    print(f\"Lade {zip_filename} herunter...\")\n",
    "    print(f\"  ‚Ä¢ {len(results)} JSON-Dateien\")\n",
    "    \n",
    "    graph_count = sum(1 for r in results if 'graph_path' in r and os.path.exists(r['graph_path']))\n",
    "    if graph_count > 0:\n",
    "        print(f\"  ‚Ä¢ {graph_count} PNG-Grafiken\")\n",
    "    \n",
    "    files.download(zip_path)\n",
    "    print(f\"\\n‚úì Download gestartet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c278fd",
   "metadata": {},
   "source": [
    "## Hilfe & Troubleshooting\n",
    "\n",
    "| Problem | L√∂sung |\n",
    "|---------|--------|\n",
    "| **NameError: api_key not defined** | F√ºhre die Zelle \"API-Konfiguration\" aus |\n",
    "| **Ung√ºltiger API-Schl√ºssel** | Pr√ºfe ob der Schl√ºssel korrekt kopiert wurde |\n",
    "| **Rate Limit Error** | Warte kurz und versuche es erneut |\n",
    "| **Timeout** | Versuche es mit weniger oder kleineren Dateien |\n",
    "| **Keine Triples extrahiert** | Erh√∂he den Detailgrad oder passe den Prompt an |\n",
    "| **JSON Parse Error** | Aktiviere \"Debug-Modus\" in der Konfiguration |\n",
    "\n",
    "**API-Schl√ºssel erhalten:**\n",
    "- Gemini: https://aistudio.google.com/apikey\n",
    "- ChatAI: https://chat-ai.academiccloud.de/\n",
    "- OpenAI: https://platform.openai.com/api-keys"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
