{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Setup** (einmal ausführen) { display-mode: \"form\" }\n",
    "#@markdown Installiert benötigte Pakete und lädt den Code.\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Pakete installieren\n",
    "!pip install -q pyyaml requests plotly networkx kaleido\n",
    "\n",
    "# Arbeitsverzeichnis erstellen\n",
    "!mkdir -p /content/triple-colab/src\n",
    "!mkdir -p /content/triple-colab/output_json\n",
    "!mkdir -p /content/triple-colab/logs\n",
    "\n",
    "# Python-Path erweitern\n",
    "if '/content/triple-colab/src' not in sys.path:\n",
    "    sys.path.insert(0, '/content/triple-colab/src')\n",
    "\n",
    "# file_client.py erstellen\n",
    "file_client_code = '''\"\"\"Datei-Client für XML/TXT-Dateien mit TEI-Optimierung.\"\"\"\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import Optional\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class FileClient:\n",
    "    \"\"\"Client zum Lesen von XML/TXT-Dateien mit TEI-Optimierung.\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = file_path\n",
    "        self.file_extension = os.path.splitext(file_path)[1].lower()\n",
    "    \n",
    "    def read_content(self) -> Optional[str]:\n",
    "        \"\"\"Liest den Dateiinhalt und extrahiert relevanten Text.\"\"\"\n",
    "        try:\n",
    "            if self.file_extension == \".xml\":\n",
    "                return self._read_xml()\n",
    "            elif self.file_extension == \".txt\":\n",
    "                return self._read_txt()\n",
    "            else:\n",
    "                logger.warning(f\"Nicht unterstütztes Dateiformat: {self.file_extension}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Fehler beim Lesen von {self.file_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _read_xml(self) -> Optional[str]:\n",
    "        \"\"\"Liest XML-Datei und extrahiert TEI-Body-Text.\"\"\"\n",
    "        try:\n",
    "            tree = ET.parse(self.file_path)\n",
    "            root = tree.getroot()\n",
    "            namespaces = {\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "            body = root.find(\".//tei:body\", namespaces)\n",
    "            if body is not None:\n",
    "                return self._extract_text_from_element(body)\n",
    "            body = root.find(\".//body\")\n",
    "            if body is not None:\n",
    "                return self._extract_text_from_element(body)\n",
    "            return self._extract_text_from_element(root)\n",
    "        except ET.ParseError as e:\n",
    "            logger.error(f\"XML-Parse-Fehler in {self.file_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _read_txt(self) -> Optional[str]:\n",
    "        \"\"\"Liest TXT-Datei.\"\"\"\n",
    "        with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    \n",
    "    def _extract_text_from_element(self, element) -> str:\n",
    "        \"\"\"Extrahiert rekursiv Text aus XML-Element.\"\"\"\n",
    "        texts = []\n",
    "        if element.text:\n",
    "            texts.append(element.text.strip())\n",
    "        for child in element:\n",
    "            texts.append(self._extract_text_from_element(child))\n",
    "            if child.tail:\n",
    "                texts.append(child.tail.strip())\n",
    "        return \" \".join(filter(None, texts))\n",
    "'''\n",
    "\n",
    "with open('/content/triple-colab/src/file_client.py', 'w') as f:\n",
    "    f.write(file_client_code)\n",
    "\n",
    "# openwebui_client.py erstellen\n",
    "openwebui_client_code = '''\"\"\"OpenWebUI-kompatibler Client mit Gemini/OpenAI-Support.\"\"\"\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class OpenWebUIClient:\n",
    "    \"\"\"Client für OpenAI-kompatible APIs (inkl. Gemini).\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, base_url: str, model: str, temperature: float = 0.1):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.max_retries = 3\n",
    "        self.retry_delay = 2\n",
    "    \n",
    "    def generate_response(self, prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:\n",
    "        \"\"\"Generiert Antwort mit automatischem Retry.\"\"\"\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                if \"generativelanguage.googleapis.com\" in self.base_url:\n",
    "                    return self._call_gemini_api(prompt, system_prompt)\n",
    "                else:\n",
    "                    return self._call_openai_api(prompt, system_prompt)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Versuch {attempt + 1}/{self.max_retries} fehlgeschlagen: {e}\")\n",
    "                if attempt < self.max_retries - 1:\n",
    "                    time.sleep(self.retry_delay * (attempt + 1))\n",
    "                else:\n",
    "                    logger.error(f\"Alle Versuche fehlgeschlagen: {e}\")\n",
    "                    return None\n",
    "    \n",
    "    def _call_gemini_api(self, prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:\n",
    "        \"\"\"Ruft Gemini API auf.\"\"\"\n",
    "        url = f\"{self.base_url}:generateContent?key={self.api_key}\"\n",
    "        payload = {\n",
    "            \"contents\": [{\"parts\": [{\"text\": prompt}]}],\n",
    "            \"generationConfig\": {\"temperature\": self.temperature}\n",
    "        }\n",
    "        if system_prompt:\n",
    "            payload[\"systemInstruction\"] = {\"parts\": [{\"text\": system_prompt}]}\n",
    "        response = requests.post(url, json=payload, timeout=120)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "    \n",
    "    def _call_openai_api(self, prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:\n",
    "        \"\"\"Ruft OpenAI-kompatible API auf.\"\"\"\n",
    "        url = f\"{self.base_url}/chat/completions\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        messages = []\n",
    "        if system_prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": self.temperature\n",
    "        }\n",
    "        response = requests.post(url, headers=headers, json=payload, timeout=120)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "'''\n",
    "\n",
    "with open('/content/triple-colab/src/openwebui_client.py', 'w') as f:\n",
    "    f.write(openwebui_client_code)\n",
    "\n",
    "print(\"✓ Setup abgeschlossen!\")\n",
    "print(\"✓ Pakete installiert\")\n",
    "print(\"✓ Code-Module erstellt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f367c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **API-Konfiguration** { display-mode: \"form\" }\n",
    "\n",
    "#@markdown ### Wähle deinen API-Provider:\n",
    "api_provider = \"Gemini (Google)\" #@param [\"Gemini (Google)\", \"ChatAI (AcademicCloud)\", \"Eigene OpenAI-API\"]\n",
    "\n",
    "#@markdown ### API-Schlüssel:\n",
    "#@markdown **Wichtig:** Gib niemals deinen API-Schlüssel in öffentlichen Notebooks weiter! Lösche ihn vor dem Teilen.\n",
    "api_key = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### Eigenes Modell (optional):\n",
    "#@markdown Leer lassen für Standard-Modell des Providers\n",
    "custom_model = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### Detailgrad der Extraktion:\n",
    "#@markdown Wie ausführlich sollen die Triples sein? (1=nur Kernaussagen, 10=sehr detailliert)\n",
    "granularity = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
    "\n",
    "#@markdown ### Temperatur (Kreativität):\n",
    "#@markdown Wie kreativ soll die KI antworten? (0=deterministisch, 1=sehr kreativ)\n",
    "temperature = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "\n",
    "#@markdown ### Erweiterte Optionen:\n",
    "#@markdown Datei-Metadaten in Ergebnissen speichern (Dateiname, Datum, etc.):\n",
    "save_file_metadata = True #@param {type:\"boolean\"}\n",
    "#@markdown Debug-Modus: Zeige KI-Antworten bei Fehlern (hilft bei Problemanalyse):\n",
    "show_debug_output = False #@param {type:\"boolean\"}\n",
    "\n",
    "# API-Schlüssel validieren\n",
    "if not api_key or len(api_key.strip()) < 10:\n",
    "    raise ValueError(\n",
    "        \"❌ Ungültiger API-Schlüssel!\\n\\n\"\n",
    "        \"Bitte gib einen gültigen API-Schlüssel ein.\\n\\n\"\n",
    "        \"API-Schlüssel erhalten:\\n\"\n",
    "        \"• Gemini: https://aistudio.google.com/apikey\\n\"\n",
    "        \"• ChatAI: https://chat-ai.academiccloud.de/\\n\"\n",
    "        \"• OpenAI: https://platform.openai.com/api-keys\"\n",
    "    )\n",
    "\n",
    "# Konfiguration basierend auf Provider\n",
    "if api_provider == \"Gemini (Google)\":\n",
    "    if custom_model:\n",
    "        selected_model = custom_model\n",
    "        base_url = f\"https://generativelanguage.googleapis.com/v1beta/models/{custom_model}\"\n",
    "    else:\n",
    "        selected_model = \"gemini-2.0-flash\"\n",
    "        base_url = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash\"\n",
    "elif api_provider == \"ChatAI (AcademicCloud)\":\n",
    "    selected_model = custom_model if custom_model else \"llama-3.3-70b-instruct\"\n",
    "    base_url = \"https://chat-ai.academiccloud.de/v1\"\n",
    "else:\n",
    "    selected_model = custom_model if custom_model else \"gpt-4o-mini\"\n",
    "    base_url = \"https://api.openai.com/v1\"\n",
    "\n",
    "# Konfiguration speichern\n",
    "selected_config = {\n",
    "    'provider': api_provider,\n",
    "    'api_key': api_key,\n",
    "    'base_url': base_url,\n",
    "    'model': selected_model,\n",
    "    'temperature': temperature,\n",
    "    'granularity': granularity,\n",
    "    'include_metadata': save_file_metadata,\n",
    "    'verbose': show_debug_output\n",
    "}\n",
    "\n",
    "print(f\"✓ Konfiguration gespeichert\")\n",
    "print(f\"  Provider: {api_provider}\")\n",
    "print(f\"  Modell: {selected_model}\")\n",
    "print(f\"  Detailgrad: {granularity}\")\n",
    "print(f\"  Temperatur: {temperature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d7a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **System-Prompt bearbeiten** (optional) { display-mode: \"form\" }\n",
    "#@markdown Hier kannst du den System-Prompt anpassen. Nur relevant wenn \"Eigenen Prompt verwenden\" aktiviert ist.\n",
    "\n",
    "#@markdown ### Eigenen System-Prompt verwenden:\n",
    "use_custom_prompt = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ### System-Prompt:\n",
    "CUSTOM_PROMPT = \"\"\"Du bist ein Experte für die Analyse historischer Briefe und die Extraktion von Wissensgraphen.\n",
    "\n",
    "Deine Aufgabe ist es, aus dem gegebenen Brieftext semantische Triples im Format (Subjekt, Prädikat, Objekt) zu extrahieren.\n",
    "\n",
    "Beachte dabei:\n",
    "- Extrahiere nur faktische Beziehungen, keine Interpretationen\n",
    "- Verwende klare, präzise Prädikate\n",
    "- Normalisiere Entitäten (z.B. \"J. W. v. Goethe\" -> \"Johann Wolfgang von Goethe\")\n",
    "- Berücksichtige historischen Kontext\n",
    "- Extrahiere sowohl explizite als auch implizite Beziehungen\n",
    "\n",
    "Antworte ausschließlich im JSON-Format mit folgendem Schema:\n",
    "{\n",
    "  \"triples\": [\n",
    "    {\"subject\": \"...\", \"predicate\": \"...\", \"object\": \"...\"}\n",
    "  ]\n",
    "}\"\"\" #@param {type:\"string\"}\n",
    "\n",
    "if use_custom_prompt:\n",
    "    print(\"✓ Eigener System-Prompt aktiviert\")\n",
    "    print(f\"  Länge: {len(CUSTOM_PROMPT)} Zeichen\")\n",
    "else:\n",
    "    print(\"ℹ Standard-Prompt wird verwendet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88338e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Dateien hochladen** { display-mode: \"form\" }\n",
    "#@markdown Klicke auf \"Dateien auswählen\" und wähle deine XML-Dateien oder ein ZIP-Archiv.\n",
    "\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# Upload-Verzeichnis vorbereiten\n",
    "upload_dir = '/content/triple-colab/uploads'\n",
    "if os.path.exists(upload_dir):\n",
    "    shutil.rmtree(upload_dir)\n",
    "os.makedirs(upload_dir)\n",
    "\n",
    "print(\"Bitte wähle deine Dateien aus...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Hochgeladene Dateien verarbeiten\n",
    "uploaded_files = []\n",
    "for filename, content in uploaded.items():\n",
    "    filepath = os.path.join(upload_dir, filename)\n",
    "    with open(filepath, 'wb') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    # ZIP-Archive entpacken\n",
    "    if filename.endswith('.zip'):\n",
    "        print(f\"Entpacke {filename}...\")\n",
    "        with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(upload_dir)\n",
    "        os.remove(filepath)\n",
    "\n",
    "# XML-Dateien sammeln\n",
    "for root, dirs, files_in_dir in os.walk(upload_dir):\n",
    "    for file in files_in_dir:\n",
    "        if file.endswith('.xml'):\n",
    "            uploaded_files.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"\\n✓ {len(uploaded_files)} XML-Datei(en) gefunden:\")\n",
    "for f in uploaded_files[:5]:\n",
    "    print(f\"  • {os.path.basename(f)}\")\n",
    "if len(uploaded_files) > 5:\n",
    "    print(f\"  ... und {len(uploaded_files) - 5} weitere\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f1c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Verarbeitung starten** { display-mode: \"form\" }\n",
    "#@markdown Startet die Triple-Extraktion für alle hochgeladenen Dateien.\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "from file_client import FileClient\n",
    "from openwebui_client import OpenWebUIClient\n",
    "\n",
    "# Validierung\n",
    "if 'selected_config' not in globals():\n",
    "    raise ValueError(\n",
    "        \"❌ Keine API-Konfiguration gefunden!\\n\\n\"\n",
    "        \"Bitte führe zuerst die Zelle 'API-Konfiguration' aus.\"\n",
    "    )\n",
    "\n",
    "if 'api_key' not in globals() or not api_key:\n",
    "    raise ValueError(\n",
    "        \"❌ Kein API-Schlüssel gefunden!\\n\\n\"\n",
    "        \"Bitte führe die Zelle 'API-Konfiguration' aus und gib deinen API-Schlüssel ein.\"\n",
    "    )\n",
    "\n",
    "if 'uploaded_files' not in globals() or not uploaded_files:\n",
    "    raise ValueError(\n",
    "        \"❌ Keine Dateien hochgeladen!\\n\\n\"\n",
    "        \"Bitte führe zuerst die Zelle 'Dateien hochladen' aus.\"\n",
    "    )\n",
    "\n",
    "# Client initialisieren\n",
    "client = OpenWebUIClient(\n",
    "    api_key=selected_config['api_key'],\n",
    "    base_url=selected_config['base_url'],\n",
    "    model=selected_config['model'],\n",
    "    temperature=selected_config['temperature']\n",
    ")\n",
    "\n",
    "# System-Prompt\n",
    "system_prompt = CUSTOM_PROMPT if ('use_custom_prompt' in globals() and use_custom_prompt) else None\n",
    "\n",
    "# Prompt-Template\n",
    "def create_prompt(text, granularity):\n",
    "    return f\"\"\"Extrahiere semantische Triples aus folgendem historischen Brieftext.\n",
    "\n",
    "Granularität: {granularity}/10 (1=grob, 10=sehr detailliert)\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Antworte NUR mit gültigem JSON im Format:\n",
    "{{\n",
    "  \"triples\": [\n",
    "    {{\"subject\": \"...\", \"predicate\": \"...\", \"object\": \"...\"}}\n",
    "  ]\n",
    "}}\"\"\"\n",
    "\n",
    "# Verarbeitung\n",
    "results = []\n",
    "output_dir = '/content/triple-colab/output_json'\n",
    "\n",
    "print(f\"Verarbeite {len(uploaded_files)} Datei(en)...\\n\")\n",
    "\n",
    "for i, filepath in enumerate(uploaded_files, 1):\n",
    "    filename = os.path.basename(filepath)\n",
    "    print(f\"[{i}/{len(uploaded_files)}] {filename}\")\n",
    "    \n",
    "    try:\n",
    "        # Text einlesen\n",
    "        file_client = FileClient(filepath)\n",
    "        text = file_client.read_content()\n",
    "        \n",
    "        if not text:\n",
    "            print(f\"  ⚠ Konnte Text nicht extrahieren\")\n",
    "            continue\n",
    "        \n",
    "        # API-Anfrage\n",
    "        prompt = create_prompt(text, selected_config['granularity'])\n",
    "        response = client.generate_response(prompt, system_prompt)\n",
    "        \n",
    "        if not response:\n",
    "            print(f\"  ❌ Keine Antwort erhalten\")\n",
    "            continue\n",
    "        \n",
    "        # JSON parsen\n",
    "        try:\n",
    "            clean_response = response.strip()\n",
    "            if clean_response.startswith('```'):\n",
    "                clean_response = '\\n'.join(clean_response.split('\\n')[1:-1])\n",
    "            if clean_response.startswith('json'):\n",
    "                clean_response = '\\n'.join(clean_response.split('\\n')[1:])\n",
    "            \n",
    "            data = json.loads(clean_response)\n",
    "            triple_count = len(data.get('triples', []))\n",
    "            \n",
    "            # Ergebnis speichern\n",
    "            output_filename = os.path.splitext(filename)[0] + '.json'\n",
    "            output_path = os.path.join(output_dir, output_filename)\n",
    "            \n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            results.append({\n",
    "                'filename': filename,\n",
    "                'triples': data.get('triples', []),\n",
    "                'output_path': output_path\n",
    "            })\n",
    "            \n",
    "            print(f\"  ✓ {triple_count} Triples extrahiert\")\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"  ❌ JSON-Parse-Fehler: {e}\")\n",
    "            if selected_config.get('verbose', False):\n",
    "                print(f\"  Response: {response[:200]}...\")\n",
    "            continue\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Fehler: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✓ Verarbeitung abgeschlossen!\")\n",
    "print(f\"  {len(results)} von {len(uploaded_files)} Dateien erfolgreich verarbeitet\")\n",
    "total_triples = sum(len(r['triples']) for r in results)\n",
    "print(f\"  {total_triples} Triples gesamt extrahiert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf617d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Ergebnis visualisieren** { display-mode: \"form\" }\n",
    "#@markdown Zeigt den Wissensgraphen für das zuletzt verarbeitete Ergebnis.\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "\n",
    "if 'results' not in globals() or not results:\n",
    "    print(\"❌ Keine Ergebnisse vorhanden. Bitte führe zuerst die Verarbeitung aus.\")\n",
    "else:\n",
    "    last_result = results[-1]\n",
    "    triples = last_result['triples']\n",
    "    \n",
    "    if not triples:\n",
    "        print(\"⚠ Keine Triples zum Visualisieren gefunden.\")\n",
    "    else:\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        for triple in triples:\n",
    "            subj = triple.get('subject', '')\n",
    "            pred = triple.get('predicate', '')\n",
    "            obj = triple.get('object', '')\n",
    "            G.add_edge(subj, obj, label=pred)\n",
    "        \n",
    "        pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "        \n",
    "        edge_trace = []\n",
    "        for edge in G.edges():\n",
    "            x0, y0 = pos[edge[0]]\n",
    "            x1, y1 = pos[edge[1]]\n",
    "            edge_trace.append(\n",
    "                go.Scatter(\n",
    "                    x=[x0, x1, None],\n",
    "                    y=[y0, y1, None],\n",
    "                    mode='lines',\n",
    "                    line=dict(width=1, color='#888'),\n",
    "                    hoverinfo='none'\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        node_x = []\n",
    "        node_y = []\n",
    "        node_text = []\n",
    "        \n",
    "        for node in G.nodes():\n",
    "            x, y = pos[node]\n",
    "            node_x.append(x)\n",
    "            node_y.append(y)\n",
    "            node_text.append(node)\n",
    "        \n",
    "        node_trace = go.Scatter(\n",
    "            x=node_x,\n",
    "            y=node_y,\n",
    "            mode='markers+text',\n",
    "            text=node_text,\n",
    "            textposition='top center',\n",
    "            hoverinfo='text',\n",
    "            marker=dict(\n",
    "                size=20,\n",
    "                color='lightblue',\n",
    "                line=dict(width=2, color='darkblue')\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig = go.Figure(\n",
    "            data=edge_trace + [node_trace],\n",
    "            layout=go.Layout(\n",
    "                title=f\"Wissensgraph: {last_result['filename']}\",\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=0, l=0, r=0, t=40),\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                height=600\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "        print(f\"\\nGraph mit {len(G.nodes())} Entitäten und {len(G.edges())} Beziehungen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fff0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Ergebnisse als ZIP herunterladen** { display-mode: \"form\" }\n",
    "#@markdown Lädt alle JSON-Ergebnisse als ZIP-Archiv herunter.\n",
    "\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "if 'results' not in globals() or not results:\n",
    "    print(\"❌ Keine Ergebnisse vorhanden. Bitte führe zuerst die Verarbeitung aus.\")\n",
    "else:\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    zip_filename = f'triple_extraction_results_{timestamp}.zip'\n",
    "    zip_path = f'/content/{zip_filename}'\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        for result in results:\n",
    "            output_path = result['output_path']\n",
    "            arcname = os.path.basename(output_path)\n",
    "            zipf.write(output_path, arcname)\n",
    "    \n",
    "    print(f\"Lade {zip_filename} herunter...\")\n",
    "    files.download(zip_path)\n",
    "    print(f\"✓ Download gestartet ({len(results)} Dateien)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c278fd",
   "metadata": {},
   "source": [
    "## Hilfe & Troubleshooting\n",
    "\n",
    "| Problem | Lösung |\n",
    "|---------|--------|\n",
    "| **NameError: api_key not defined** | Führe die Zelle \"API-Konfiguration\" aus |\n",
    "| **Ungültiger API-Schlüssel** | Prüfe ob der Schlüssel korrekt kopiert wurde |\n",
    "| **Rate Limit Error** | Warte kurz und versuche es erneut |\n",
    "| **Timeout** | Versuche es mit weniger oder kleineren Dateien |\n",
    "| **Keine Triples extrahiert** | Erhöhe den Detailgrad oder passe den Prompt an |\n",
    "| **JSON Parse Error** | Aktiviere \"Debug-Modus\" in der Konfiguration |\n",
    "\n",
    "**API-Schlüssel erhalten:**\n",
    "- Gemini: https://aistudio.google.com/apikey\n",
    "- ChatAI: https://chat-ai.academiccloud.de/\n",
    "- OpenAI: https://platform.openai.com/api-keys"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
